{"version":3,"sources":["/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql-tag/src/index.js","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/jsutils/invariant.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/language/source.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/language/location.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/error/printError.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/error/GraphQLError.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/error/syntaxError.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/error/formatError.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/language/blockStringValue.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/language/lexer.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/language/kinds.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/language/directiveLocation.mjs","/Users/bgcooper/Code/Tweener/MyApp/node_modules/graphql/language/parser.mjs"],"names":["parse","__webpack_require__","normalize","string","replace","trim","docCache","fragmentSourceMap","printFragmentWarnings","experimentalFragmentVariables","parseDocument","doc","cacheKey","parsed","kind","Error","stripLoc","removeLocAtThisLevel","docType","Object","prototype","toString","call","map","d","loc","startToken","endToken","key","value","valueType","keys","hasOwnProperty","ast","astFragmentMap","definitions","i","length","fragmentDefinition","fragmentName","name","sourceKey","source","body","substring","start","end","console","warn","push","processFragments","gql","args","Array","slice","arguments","literals","result","default","resetCaches","disableFragmentWarnings","enableExperimentalFragmentVariables","disableExperimentalFragmentVariables","module","exports","invariant","condition","message","source_Source","Source","locationOffset","instance","Constructor","TypeError","source_classCallCheck","this","line","column","getLocation","position","lineRegexp","match","exec","index","printError_highlightSourceAtLocation","location","lineOffset","columnOffset","printError_getColumnOffset","contextLine","contextColumn","prevLineNum","lineNum","nextLineNum","padLen","lines","split","printError_whitespace","printError_lpad","filter","Boolean","join","len","str","GraphQLError_GraphQLError","nodes","positions","path","originalError","extensions","_nodes","isArray","undefined","_source","node","_positions","reduce","list","_locations","pos","defineProperties","enumerable","writable","locations","stack","defineProperty","configurable","captureStackTrace","syntaxError_syntaxError","description","create","constructor","error","printedLocations","forEach","concat","printError_printError","assign","blockStringValue","rawString","commonIndent","indent","leadingWhitespace","_i","isBlank","shift","pop","lexer_createLexer","options","startOfFileToken","lexer_Tok","lexer_TokenKind","SOF","lastToken","token","lineStart","advance","lexer_advanceLexer","lookahead","lexer_lookahead","EOF","next","lexer_readToken","COMMENT","freeze","BANG","DOLLAR","AMP","PAREN_L","PAREN_R","SPREAD","COLON","EQUALS","AT","BRACKET_L","BRACKET_R","BRACE_L","PIPE","BRACE_R","NAME","INT","FLOAT","STRING","BLOCK_STRING","lexer_getTokenDesc","lexer_charCodeAt","String","charCodeAt","lexer_slice","prev","lexer_printCharCode","code","isNaN","JSON","stringify","fromCharCode","toUpperCase","lexer","bodyLength","startPosition","lexer_positionAfterWhitespace","col","lexer_readComment","lexer_readName","firstCode","isFloat","lexer_readDigits","lexer_readNumber","chunkStart","rawValue","lexer_readBlockString","charCode","a","b","c","lexer_char2hex","lexer_readString","lexer_unexpectedCharacterMessage","toJSON","inspect","Kind","DOCUMENT","OPERATION_DEFINITION","VARIABLE_DEFINITION","VARIABLE","SELECTION_SET","FIELD","ARGUMENT","FRAGMENT_SPREAD","INLINE_FRAGMENT","FRAGMENT_DEFINITION","BOOLEAN","NULL","ENUM","LIST","OBJECT","OBJECT_FIELD","DIRECTIVE","NAMED_TYPE","LIST_TYPE","NON_NULL_TYPE","SCHEMA_DEFINITION","OPERATION_TYPE_DEFINITION","SCALAR_TYPE_DEFINITION","OBJECT_TYPE_DEFINITION","FIELD_DEFINITION","INPUT_VALUE_DEFINITION","INTERFACE_TYPE_DEFINITION","UNION_TYPE_DEFINITION","ENUM_TYPE_DEFINITION","ENUM_VALUE_DEFINITION","INPUT_OBJECT_TYPE_DEFINITION","SCALAR_TYPE_EXTENSION","OBJECT_TYPE_EXTENSION","INTERFACE_TYPE_EXTENSION","UNION_TYPE_EXTENSION","ENUM_TYPE_EXTENSION","INPUT_OBJECT_TYPE_EXTENSION","DIRECTIVE_DEFINITION","DirectiveLocation","QUERY","MUTATION","SUBSCRIPTION","SCHEMA","SCALAR","ARGUMENT_DEFINITION","INTERFACE","UNION","ENUM_VALUE","INPUT_OBJECT","INPUT_FIELD_DEFINITION","parser_parse","sourceObj","parser_expect","parser_parseDefinition","parser_skip","parser_loc","parser_parseDocument","parser_parseValue","parser_parseValueLiteral","parser_parseType","type","parser_parseTypeReference","parser_parseName","parser_peek","parser_parseExecutableDefinition","parser_parseTypeSystemDefinition","parser_peekDescription","parser_unexpected","parser_parseOperationDefinition","parser_expectKeyword","parser_parseFragmentName","variableDefinitions","parser_parseVariableDefinitions","typeCondition","parser_parseNamedType","directives","parser_parseDirectives","selectionSet","parser_parseSelectionSet","parser_parseFragmentDefinition","operation","parser_parseOperationType","operationToken","parser_many","parser_parseVariableDefinition","variable","parser_parseVariable","defaultValue","selections","parser_parseSelection","parser_parseFragment","nameOrAlias","alias","parser_parseArguments","parser_parseField","isConst","item","parser_parseConstArgument","parser_parseArgument","parser_parseConstValue","parser_parseValueValue","values","openKind","parseFn","closeKind","parser_any","parser_parseList","fields","parser_parseObjectField","parser_parseObject","parser_parseStringLiteral","block","parser_parseDirective","keywordToken","operationTypes","parser_parseOperationTypeDefinition","parser_parseSchemaDefinition","parser_parseDescription","parser_parseScalarTypeDefinition","interfaces","parser_parseImplementsInterfaces","parser_parseFieldsDefinition","parser_parseObjectTypeDefinition","parser_parseInterfaceTypeDefinition","types","parser_parseUnionMemberTypes","parser_parseUnionTypeDefinition","parser_parseEnumValuesDefinition","parser_parseEnumTypeDefinition","parser_parseInputFieldsDefinition","parser_parseInputObjectTypeDefinition","parser_parseScalarTypeExtension","parser_parseObjectTypeExtension","parser_parseInterfaceTypeExtension","parser_parseUnionTypeExtension","parser_parseEnumTypeExtension","parser_parseInputObjectTypeExtension","parser_parseTypeExtension","parser_parseArgumentDefs","parser_parseDirectiveLocation","parser_parseDirectiveLocations","parser_parseDirectiveDefinition","allowLegacySDLImplementsInterfaces","allowLegacySDLEmptyFields","parser_parseFieldDefinition","parser_parseInputValueDef","parser_parseEnumValueDefinition","noLocation","parser_Loc","atToken","__webpack_exports__"],"mappings":"6EAAA,IAEAA,EAFAC,EAAA,KAEAD,MAIA,SAAAE,EAAAC,GACA,OAAAA,EAAAC,QAAA,eAAAC,OAIA,IAAAC,KAGAC,KAeA,IAAAC,GAAA,EA2FA,IAAAC,GAAA,EACA,SAAAC,EAAAC,GACA,IAAAC,EAAAV,EAAAS,GAEA,GAAAL,EAAAM,GACA,OAAAN,EAAAM,GAGA,IAAAC,EAAAb,EAAAW,GAA2BF,kCAC3B,IAAAI,GAAA,aAAAA,EAAAC,KACA,UAAAC,MAAA,iCASA,OAHAF,EA5DA,SAAAG,EAAAL,EAAAM,GACA,IAAAC,EAAAC,OAAAC,UAAAC,SAAAC,KAAAX,GAEA,sBAAAO,EACA,OAAAP,EAAAY,IAAA,SAAAC,GACA,OAAAR,EAAAQ,EAAAP,KAIA,uBAAAC,EACA,UAAAH,MAAA,qBAKAE,GAAAN,EAAAc,YACAd,EAAAc,IAIAd,EAAAc,aACAd,EAAAc,IAAAC,kBACAf,EAAAc,IAAAE,UAGA,IACAC,EACAC,EACAC,EAHAC,EAAAZ,OAAAY,KAAApB,GAKA,IAAAiB,KAAAG,EACAA,EAAAC,eAAAJ,KACAC,EAAAlB,EAAAoB,EAAAH,IAGA,qBAFAE,EAAAX,OAAAC,UAAAC,SAAAC,KAAAO,KAEA,mBAAAC,IACAnB,EAAAoB,EAAAH,IAAAZ,EAAAa,GAAA,KAKA,OAAAlB,EAmBAK,CADAH,EAzGA,SAAAoB,GAIA,IAHA,IAfAR,EAeAS,KACAC,KAEAC,EAAA,EAAiBA,EAAAH,EAAAE,YAAAE,OAA4BD,IAAA,CAC7C,IAAAE,EAAAL,EAAAE,YAAAC,GAEA,0BAAAE,EAAAxB,KAAA,CACA,IAAAyB,EAAAD,EAAAE,KAAAX,MACAY,EAtBAvC,GADAuB,EAuBAa,EAAAb,KAtBAiB,OAAAC,KAAAC,UAAAnB,EAAAoB,MAAApB,EAAAqB,MAyBAvC,EAAAyB,eAAAO,KAAAhC,EAAAgC,GAAAE,IAIAjC,GACAuC,QAAAC,KAAA,+BAAAT,EAAA,iMAKAhC,EAAAgC,GAAAE,IAAA,GAEOlC,EAAAyB,eAAAO,KACPhC,EAAAgC,MACAhC,EAAAgC,GAAAE,IAAA,GAGAP,EAAAO,KACAP,EAAAO,IAAA,EACAN,EAAAc,KAAAX,SAGAH,EAAAc,KAAAX,GAKA,OADAL,EAAAE,cACAF,EAkEAiB,CAAArC,IACA,GACAP,EAAAM,GAAAC,EAEAA,EAYA,SAAAsC,IAQA,IAPA,IAAAC,EAAAC,MAAAjC,UAAAkC,MAAAhC,KAAAiC,WAEAC,EAAAJ,EAAA,GAGAK,EAAA,mBAAAD,IAAA,GAEApB,EAAA,EAAiBA,EAAAgB,EAAAf,OAAiBD,IAClCgB,EAAAhB,IAAAgB,EAAAhB,GAAAtB,MAAA,aAAAsC,EAAAhB,GAAAtB,KACA2C,GAAAL,EAAAhB,GAAAX,IAAAiB,OAAAC,KAEAc,GAAAL,EAAAhB,GAGAqB,GAAAD,EAAApB,GAGA,OAAA1B,EAAA+C,GAIAN,EAAAO,QAAAP,EACAA,EAAAQ,YAzJA,WACArD,KACAC,MAwJA4C,EAAAS,wBAvGA,WACApD,GAAA,GAuGA2C,EAAAU,oCAlCA,WACApD,GAAA,GAkCA0C,EAAAW,qCA/BA,WACArD,GAAA,GAgCAsD,EAAAC,QAAAb,oCC1KA,SAAAc,EAAAC,EAAAC,GAEA,IAAAD,EACA,UAAAnD,MAAAoD,UCSA,IAAAC,EAAA,SAAAC,EAAA1B,EAAAH,EAAA8B,IArBA,SAAAC,EAAAC,GAAiD,KAAAD,aAAAC,GAA0C,UAAAC,UAAA,qCAsB3FC,CAAAC,KAAAN,GAEAM,KAAAhC,OACAgC,KAAAnC,QAAA,kBACAmC,KAAAL,mBAA2CM,KAAA,EAAAC,OAAA,GAC3CF,KAAAL,eAAAM,KAAA,GAAAX,EAAA,8DACAU,KAAAL,eAAAO,OAAA,GAAAZ,EAAA,iECbA,SAAAa,EAAApC,EAAAqC,GAKA,IAJA,IAAAC,EAAA,eACAJ,EAAA,EACAC,EAAAE,EAAA,EACAE,OAAA,GACAA,EAAAD,EAAAE,KAAAxC,EAAAC,QAAAsC,EAAAE,MAAAJ,GACAH,GAAA,EACAC,EAAAE,EAAA,GAAAE,EAAAE,MAAAF,EAAA,GAAA5C,QAEA,OAAUuC,OAAAC,UCaV,SAAAO,EAAA1C,EAAA2C,GACA,IAAAT,EAAAS,EAAAT,KACAU,EAAA5C,EAAA4B,eAAAM,KAAA,EACAW,EAaA,SAAA7C,EAAA2C,GACA,WAAAA,EAAAT,KAAAlC,EAAA4B,eAAAO,OAAA,IAdAW,CAAA9C,EAAA2C,GACAI,EAAAb,EAAAU,EACAI,EAAAL,EAAAR,OAAAU,EACAI,GAAAF,EAAA,GAAApE,WACAuE,EAAAH,EAAApE,WACAwE,GAAAJ,EAAA,GAAApE,WACAyE,EAAAD,EAAAxD,OACA0D,EAAArD,EAAAC,KAAAqD,MAAA,gBAGA,OAFAD,EAAA,GAAAE,EAAAvD,EAAA4B,eAAAO,OAAA,GAAAkB,EAAA,IACArD,EAAAF,KAAA,KAAAiD,EAAA,IAAAC,EAAA,IAAAd,GAAA,GAAAsB,EAAAJ,EAAAH,GAAA,KAAAI,EAAAnB,EAAA,GAAAsB,EAAAJ,EAAAF,GAAA,KAAAG,EAAAnB,EAAA,GAAAqB,EAAA,EAAAH,EAAAJ,EAAA,OAAAd,EAAAmB,EAAA1D,QAAA6D,EAAAJ,EAAAD,GAAA,KAAAE,EAAAnB,IACAuB,OAAAC,SAAAC,KAAA,MAOA,SAAAJ,EAAAK,GACA,OAAAjD,MAAAiD,EAAA,GAAAD,KAAA,KAGA,SAAAH,EAAAI,EAAAC,GACA,OAAAN,EAAAK,EAAAC,EAAAlE,QAAAkE,EC1CA,SAAAC,EACArC,EAAAsC,EAAA/D,EAAAgE,EAAAC,EAAAC,EAAAC,GAEA,IAAAC,EAAAzD,MAAA0D,QAAAN,GAAA,IAAAA,EAAApE,OAAAoE,OAAAO,EAAAP,WAAAO,EAGAC,EAAAvE,EACA,IAAAuE,GAAAH,EAAA,CACA,IAAAI,EAAAJ,EAAA,GACAG,EAAAC,KAAAzF,KAAAyF,EAAAzF,IAAAiB,OAGA,IAAAyE,EAAAT,GACAS,GAAAL,IACAK,EAAAL,EAAAM,OAAA,SAAAC,EAAAH,GAIA,OAHAA,EAAAzF,KACA4F,EAAApE,KAAAiE,EAAAzF,IAAAoB,OAEAwE,QAGAF,GAAA,IAAAA,EAAA9E,SACA8E,OAAAH,GAGA,IAAAM,OAAA,EACAZ,GAAAhE,EACA4E,EAAAZ,EAAAnF,IAAA,SAAAgG,GACA,OAAAzC,EAAApC,EAAA6E,KAEGT,IACHQ,EAAAR,EAAAM,OAAA,SAAAC,EAAAH,GAIA,OAHAA,EAAAzF,KACA4F,EAAApE,KAAA6B,EAAAoC,EAAAzF,IAAAiB,OAAAwE,EAAAzF,IAAAoB,QAEAwE,QAIAlG,OAAAqG,iBAAA7C,MACAR,SACAtC,MAAAsC,EAIAsD,YAAA,EACAC,UAAA,GAEAC,WAGA9F,MAAAyF,QAAAN,EAIAS,YAAA,GAEAd,MAGA9E,MAAA8E,QAAAK,EAIAS,YAAA,GAEAhB,OACA5E,MAAAiF,QAAAE,GAEAtE,QACAb,MAAAoF,QAAAD,GAEAN,WACA7E,MAAAsF,QAAAH,GAEAJ,eACA/E,MAAA+E,GAEAC,YACAhF,MAAAgF,GAAAD,KAAAC,cAKAD,KAAAgB,MACAzG,OAAA0G,eAAAlD,KAAA,SACA9C,MAAA+E,EAAAgB,MACAF,UAAA,EACAI,cAAA,IAEG/G,MAAAgH,kBACHhH,MAAAgH,kBAAApD,KAAA6B,GAEArF,OAAA0G,eAAAlD,KAAA,SACA9C,MAAAd,QAAA6G,MACAF,UAAA,EACAI,cAAA,ICpGA,SAAAE,EAAAtF,EAAAqC,EAAAkD,GACA,WAAAzB,EAAA,iBAAAyB,OAAAjB,EAAAtE,GAAAqC,IDwGAyB,EAAApF,UAAAD,OAAA+G,OAAAnH,MAAAK,WACA+G,aAAgBtG,MAAA2E,GAChBhE,MAASX,MAAA,gBACTR,UACAQ,MAAA,WACA,OD9GA,SAAAuG,GACA,IAAAC,KACA,GAAAD,EAAA3B,MACA2B,EAAA3B,MAAA6B,QAAA,SAAApB,GACAA,EAAAzF,KACA4G,EAAApF,KAAAmC,EAAA8B,EAAAzF,IAAAiB,OAAAoC,EAAAoC,EAAAzF,IAAAiB,OAAAwE,EAAAzF,IAAAoB,gBAGG,GAAAuF,EAAA1F,QAAA0F,EAAAT,UAAA,CACH,IAAAjF,EAAA0F,EAAA1F,OACA0F,EAAAT,UAAAW,QAAA,SAAAjD,GACAgD,EAAApF,KAAAmC,EAAA1C,EAAA2C,MAGA,WAAAgD,EAAAhG,OAAA+F,EAAAjE,SAAAiE,EAAAjE,SAAAoE,OAAAF,GAAAhC,KAAA,aCgGAmC,CAAA7D,UE9HAxD,OAAAsH,OCeA,SAAAC,EAAAC,GAMA,IAJA,IAAA5C,EAAA4C,EAAA3C,MAAA,gBAGA4C,EAAA,KACAxG,EAAA,EAAiBA,EAAA2D,EAAA1D,OAAkBD,IAAA,CACnC,IAAAwC,EAAAmB,EAAA3D,GACAyG,EAAAC,EAAAlE,GACA,GAAAiE,EAAAjE,EAAAvC,SAAA,OAAAuG,GAAAC,EAAAD,IAEA,KADAA,EAAAC,GAEA,MAKA,GAAAD,EACA,QAAAG,EAAA,EAAoBA,EAAAhD,EAAA1D,OAAmB0G,IACvChD,EAAAgD,GAAAhD,EAAAgD,GAAAzF,MAAAsF,GAKA,KAAA7C,EAAA1D,OAAA,GAAA2G,EAAAjD,EAAA,KACAA,EAAAkD,QAEA,KAAAlD,EAAA1D,OAAA,GAAA2G,EAAAjD,IAAA1D,OAAA,KACA0D,EAAAmD,MAIA,OAAAnD,EAAAM,KAAA,MAGA,SAAAyC,EAAAvC,GAEA,IADA,IAAAnE,EAAA,EACAA,EAAAmE,EAAAlE,SAAA,MAAAkE,EAAAnE,IAAA,OAAAmE,EAAAnE,KACAA,IAEA,OAAAA,EAGA,SAAA4G,EAAAzC,GACA,OAAAuC,EAAAvC,OAAAlE,OCvCA,SAAA8G,EAAAzG,EAAA0G,GACA,IAAAC,EAAA,IAAAC,EAAAC,EAAAC,IAAA,cAWA,OATA9G,SACA0G,UACAK,UAAAJ,EACAK,MAAAL,EACAzE,KAAA,EACA+E,UAAA,EACAC,QAAAC,EACAC,UAAAC,GAKA,SAAAF,IAGA,OAFAlF,KAAA8E,UAAA9E,KAAA+E,MACA/E,KAAA+E,MAAA/E,KAAAmF,YAIA,SAAAC,IACA,IAAAL,EAAA/E,KAAA+E,MACA,GAAAA,EAAA5I,OAAAyI,EAAAS,IACA,GAEAN,IAAAO,OAAAP,EAAAO,KAAAC,EAAAvF,KAAA+E,UACKA,EAAA5I,OAAAyI,EAAAY,SAEL,OAAAT,EAYA,IAAAH,EAAApI,OAAAiJ,QACAZ,IAAA,QACAQ,IAAA,QACAK,KAAA,IACAC,OAAA,IACAC,IAAA,IACAC,QAAA,IACAC,QAAA,IACAC,OAAA,MACAC,MAAA,IACAC,OAAA,IACAC,GAAA,IACAC,UAAA,IACAC,UAAA,IACAC,QAAA,IACAC,KAAA,IACAC,QAAA,IACAC,KAAA,OACAC,IAAA,MACAC,MAAA,QACAC,OAAA,SACAC,aAAA,cACApB,QAAA,YAWA,SAAAqB,EAAA9B,GACA,IAAA7H,EAAA6H,EAAA7H,MACA,OAAAA,EAAA6H,EAAA5I,KAAA,KAAAe,EAAA,IAAA6H,EAAA5I,KAGA,IAAA2K,EAAAC,OAAAtK,UAAAuK,WACAC,EAAAF,OAAAtK,UAAAkC,MAKA,SAAAgG,EAAAxI,EAAA+B,EAAAC,EAAA8B,EAAAC,EAAAgH,EAAAhK,GACA8C,KAAA7D,OACA6D,KAAA9B,QACA8B,KAAA7B,MACA6B,KAAAC,OACAD,KAAAE,SACAF,KAAA9C,QACA8C,KAAAkH,OACAlH,KAAAsF,KAAA,KAaA,SAAA6B,EAAAC,GACA,OAEAC,MAAAD,GAAAxC,EAAAS,IACA+B,EAAA,IAAAE,KAAAC,UAAAR,OAAAS,aAAAJ,IACA,aAAAA,EAAA1K,SAAA,IAAA+K,eAAA9I,OAAA,OAWA,SAAA4G,EAAAmC,EAAAR,GACA,IAAAnJ,EAAA2J,EAAA3J,OACAC,EAAAD,EAAAC,KACA2J,EAAA3J,EAAAN,OAEAkF,EAgKA,SAAA5E,EAAA4J,EAAAF,GACA,IAAAC,EAAA3J,EAAAN,OACA0C,EAAAwH,EACA,KAAAxH,EAAAuH,GAAA,CACA,IAAAP,EAAAN,EAAAnK,KAAAqB,EAAAoC,GAEA,OAAAgH,GAAA,KAAAA,GAAA,KAAAA,GAAA,QAAAA,IACAhH,OACK,QAAAgH,IAELhH,IACAsH,EAAAzH,KACAyH,EAAA1C,UAAA5E,MACK,SAAAgH,EAUL,MARA,KAAAN,EAAAnK,KAAAqB,EAAAoC,EAAA,GACAA,GAAA,IAEAA,IAEAsH,EAAAzH,KACAyH,EAAA1C,UAAA5E,GAKA,OAAAA,EA1LAyH,CAAA7J,EAAAkJ,EAAA/I,IAAAuJ,GACAzH,EAAAyH,EAAAzH,KACA6H,EAAA,EAAAlF,EAAA8E,EAAA1C,UAEA,GAAApC,GAAA+E,EACA,WAAAhD,EAAAC,EAAAS,IAAAsC,IAAA1H,EAAA6H,EAAAZ,GAGA,IAAAE,EAAAN,EAAAnK,KAAAqB,EAAA4E,GAGA,GAAAwE,EAAA,QAAAA,GAAA,KAAAA,GAAA,KAAAA,EACA,MAAA/D,EAAAtF,EAAA6E,EAAA,wCAAAuE,EAAAC,GAAA,KAGA,OAAAA,GAEA,QACA,WAAAzC,EAAAC,EAAAc,KAAA9C,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,OA6KA,SAAAnJ,EAAAG,EAAA+B,EAAA6H,EAAAZ,GACA,IAAAlJ,EAAAD,EAAAC,KACAoJ,OAAA,EACAhH,EAAAlC,EAEA,GACAkJ,EAAAN,EAAAnK,KAAAqB,IAAAoC,SACG,OAAAgH,IAEHA,EAAA,QAAAA,IAEA,WAAAzC,EAAAC,EAAAY,QAAAtH,EAAAkC,EAAAH,EAAA6H,EAAAZ,EAAAD,EAAAtK,KAAAqB,EAAAE,EAAA,EAAAkC,IAxLA2H,CAAAhK,EAAA6E,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,WAAAvC,EAAAC,EAAAe,OAAA/C,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,WAAAvC,EAAAC,EAAAgB,IAAAhD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,WAAAvC,EAAAC,EAAAiB,QAAAjD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,WAAAvC,EAAAC,EAAAkB,QAAAlD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,QAAAJ,EAAAnK,KAAAqB,EAAA4E,EAAA,SAAAkE,EAAAnK,KAAAqB,EAAA4E,EAAA,GACA,WAAA+B,EAAAC,EAAAmB,OAAAnD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,MAEA,QACA,WAAAvC,EAAAC,EAAAoB,MAAApD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,WAAAvC,EAAAC,EAAAqB,OAAArD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,WAAAvC,EAAAC,EAAAsB,GAAAtD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,WAAAvC,EAAAC,EAAAuB,UAAAvD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,WAAAvC,EAAAC,EAAAwB,UAAAxD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,SACA,WAAAvC,EAAAC,EAAAyB,QAAAzD,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,SACA,WAAAvC,EAAAC,EAAA0B,KAAA1D,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,SACA,WAAAvC,EAAAC,EAAA2B,QAAA3D,IAAA,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,OAmTA,SAAAnJ,EAAAG,EAAA+B,EAAA6H,EAAAZ,GACA,IAAAlJ,EAAAD,EAAAC,KACA2J,EAAA3J,EAAAN,OACA0C,EAAAlC,EAAA,EACAkJ,EAAA,EACA,KAAAhH,IAAAuH,GAAA,QAAAP,EAAAN,EAAAnK,KAAAqB,EAAAoC,MAAA,KAAAgH,GACAA,GAAA,IAAAA,GAAA,IACAA,GAAA,IAAAA,GAAA,IACAA,GAAA,IAAAA,GAAA,QAEAhH,EAEA,WAAAuE,EAAAC,EAAA4B,KAAAtI,EAAAkC,EAAAH,EAAA6H,EAAAZ,EAAAD,EAAAtK,KAAAqB,EAAAE,EAAAkC,IA/TA4H,CAAAjK,EAAA6E,EAAA3C,EAAA6H,EAAAZ,GAEA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,OAoFA,SAAAnJ,EAAAG,EAAA+J,EAAAhI,EAAA6H,EAAAZ,GACA,IAAAlJ,EAAAD,EAAAC,KACAoJ,EAAAa,EACA7H,EAAAlC,EACAgK,GAAA,EAEA,KAAAd,IAEAA,EAAAN,EAAAnK,KAAAqB,IAAAoC,IAGA,QAAAgH,GAGA,IADAA,EAAAN,EAAAnK,KAAAqB,IAAAoC,KACA,IAAAgH,GAAA,GACA,MAAA/D,EAAAtF,EAAAqC,EAAA,6CAAA+G,EAAAC,GAAA,UAGAhH,EAAA+H,EAAApK,EAAAqC,EAAAgH,GACAA,EAAAN,EAAAnK,KAAAqB,EAAAoC,GAGA,KAAAgH,IAEAc,GAAA,EAEAd,EAAAN,EAAAnK,KAAAqB,IAAAoC,GACAA,EAAA+H,EAAApK,EAAAqC,EAAAgH,GACAA,EAAAN,EAAAnK,KAAAqB,EAAAoC,IAGA,KAAAgH,GAAA,MAAAA,IAEAc,GAAA,EAGA,MADAd,EAAAN,EAAAnK,KAAAqB,IAAAoC,KACA,KAAAgH,IAEAA,EAAAN,EAAAnK,KAAAqB,IAAAoC,IAEAA,EAAA+H,EAAApK,EAAAqC,EAAAgH,IAGA,WAAAzC,EAAAuD,EAAAtD,EAAA8B,MAAA9B,EAAA6B,IAAAvI,EAAAkC,EAAAH,EAAA6H,EAAAZ,EAAAD,EAAAtK,KAAAqB,EAAAE,EAAAkC,IA/HAgI,CAAArK,EAAA6E,EAAAwE,EAAAnH,EAAA6H,EAAAZ,GAEA,QACA,YAAAJ,EAAAnK,KAAAqB,EAAA4E,EAAA,SAAAkE,EAAAnK,KAAAqB,EAAA4E,EAAA,GAiOA,SAAA7E,EAAAG,EAAA+B,EAAA6H,EAAAZ,GACA,IAAAlJ,EAAAD,EAAAC,KACAoC,EAAAlC,EAAA,EACAmK,EAAAjI,EACAgH,EAAA,EACAkB,EAAA,GAEA,KAAAlI,EAAApC,EAAAN,QAAA,QAAA0J,EAAAN,EAAAnK,KAAAqB,EAAAoC,KAAA,CAEA,QAAAgH,GAAA,KAAAN,EAAAnK,KAAAqB,EAAAoC,EAAA,SAAA0G,EAAAnK,KAAAqB,EAAAoC,EAAA,GAEA,OADAkI,GAAArB,EAAAtK,KAAAqB,EAAAqK,EAAAjI,GACA,IAAAuE,EAAAC,EAAAgC,aAAA1I,EAAAkC,EAAA,EAAAH,EAAA6H,EAAAZ,EAAAnD,EAAAuE,IAIA,GAAAlB,EAAA,QAAAA,GAAA,KAAAA,GAAA,KAAAA,EACA,MAAA/D,EAAAtF,EAAAqC,EAAA,oCAAA+G,EAAAC,GAAA,KAIA,KAAAA,GAAA,KAAAN,EAAAnK,KAAAqB,EAAAoC,EAAA,SAAA0G,EAAAnK,KAAAqB,EAAAoC,EAAA,SAAA0G,EAAAnK,KAAAqB,EAAAoC,EAAA,IACAkI,GAAArB,EAAAtK,KAAAqB,EAAAqK,EAAAjI,GAAA,MAEAiI,EADAjI,GAAA,KAGAA,EAIA,MAAAiD,EAAAtF,EAAAqC,EAAA,wBA7PAmI,CAAAxK,EAAA6E,EAAA3C,EAAA6H,EAAAZ,GAoJA,SAAAnJ,EAAAG,EAAA+B,EAAA6H,EAAAZ,GACA,IAAAlJ,EAAAD,EAAAC,KACAoC,EAAAlC,EAAA,EACAmK,EAAAjI,EACAgH,EAAA,EACAlK,EAAA,GAEA,KAAAkD,EAAApC,EAAAN,QAAA,QAAA0J,EAAAN,EAAAnK,KAAAqB,EAAAoC,KAEA,KAAAgH,GAAA,KAAAA,GAAA,CAEA,QAAAA,EAEA,OADAlK,GAAA+J,EAAAtK,KAAAqB,EAAAqK,EAAAjI,GACA,IAAAuE,EAAAC,EAAA+B,OAAAzI,EAAAkC,EAAA,EAAAH,EAAA6H,EAAAZ,EAAAhK,GAIA,GAAAkK,EAAA,QAAAA,EACA,MAAA/D,EAAAtF,EAAAqC,EAAA,oCAAA+G,EAAAC,GAAA,KAIA,KADAhH,EACA,KAAAgH,EAAA,CAIA,OAFAlK,GAAA+J,EAAAtK,KAAAqB,EAAAqK,EAAAjI,EAAA,GACAgH,EAAAN,EAAAnK,KAAAqB,EAAAoC,IAEA,QACAlD,GAAA,IACA,MACA,QACAA,GAAA,IACA,MACA,QACAA,GAAA,KACA,MACA,QACAA,GAAA,KACA,MACA,SACAA,GAAA,KACA,MACA,SACAA,GAAA,KACA,MACA,SACAA,GAAA,KACA,MACA,SACAA,GAAA,KACA,MACA,SAEA,IAAAsL,GAiEAC,EAjEA3B,EAAAnK,KAAAqB,EAAAoC,EAAA,GAiEAsI,EAjEA5B,EAAAnK,KAAAqB,EAAAoC,EAAA,GAiEAuI,EAjEA7B,EAAAnK,KAAAqB,EAAAoC,EAAA,GAiEAvD,EAjEAiK,EAAAnK,KAAAqB,EAAAoC,EAAA,GAkEAwI,EAAAH,IAAA,GAAAG,EAAAF,IAAA,EAAAE,EAAAD,IAAA,EAAAC,EAAA/L,IAjEA,GAAA2L,EAAA,EACA,MAAAnF,EAAAtF,EAAAqC,EAAA,yCAAApC,EAAAW,MAAAyB,EAAA,EAAAA,EAAA,QAEAlD,GAAA6J,OAAAS,aAAAgB,GACApI,GAAA,EACA,MACA,QACA,MAAAiD,EAAAtF,EAAAqC,EAAA,wCAAA2G,OAAAS,aAAAJ,GAAA,KAGAiB,IADAjI,GAuDA,IAAAqI,EAAAC,EAAAC,EAAA9L,EAlDA,MAAAwG,EAAAtF,EAAAqC,EAAA,wBAtNAyI,CAAA9K,EAAA6E,EAAA3C,EAAA6H,EAAAZ,GAGA,MAAA7D,EAAAtF,EAAA6E,EAMA,SAAAwE,GACA,QAAAA,EAEA,wFAGA,+CAAAD,EAAAC,GAAA,IAZA0B,CAAA1B,IA4HA,SAAAe,EAAApK,EAAAG,EAAA+J,GACA,IAAAjK,EAAAD,EAAAC,KACAoC,EAAAlC,EACAkJ,EAAAa,EACA,GAAAb,GAAA,IAAAA,GAAA,IAEA,GACAA,EAAAN,EAAAnK,KAAAqB,IAAAoC,SACKgH,GAAA,IAAAA,GAAA,IACL,OAAAhH,EAEA,MAAAiD,EAAAtF,EAAAqC,EAAA,2CAAA+G,EAAAC,GAAA,KA0IA,SAAAwB,EAAAH,GACA,OAAAA,GAAA,IAAAA,GAAA,GAAAA,EAAA,GACAA,GAAA,IAAAA,GAAA,GAAAA,EAAA,GACAA,GAAA,IAAAA,GAAA,IAAAA,EAAA,IACA,EA/bA9D,EAAAlI,UAAAsM,OAAApE,EAAAlI,UAAAuM,QAAA,WACA,OACA7M,KAAA6D,KAAA7D,KACAe,MAAA8C,KAAA9C,MACA+C,KAAAD,KAAAC,KACAC,OAAAF,KAAAE,SC9GA,IAAA+I,EAAAzM,OAAAiJ,QAEAe,KAAA,OAGA0C,SAAA,WACAC,qBAAA,sBACAC,oBAAA,qBACAC,SAAA,WACAC,cAAA,eACAC,MAAA,QACAC,SAAA,WAGAC,gBAAA,iBACAC,gBAAA,iBACAC,oBAAA,qBAGAlD,IAAA,WACAC,MAAA,aACAC,OAAA,cACAiD,QAAA,eACAC,KAAA,YACAC,KAAA,YACAC,KAAA,YACAC,OAAA,cACAC,aAAA,cAGAC,UAAA,YAGAC,WAAA,YACAC,UAAA,WACAC,cAAA,cAGAC,kBAAA,mBACAC,0BAAA,0BAGAC,uBAAA,uBACAC,uBAAA,uBACAC,iBAAA,kBACAC,uBAAA,uBACAC,0BAAA,0BACAC,sBAAA,sBACAC,qBAAA,qBACAC,sBAAA,sBACAC,6BAAA,4BAGAC,sBAAA,sBACAC,sBAAA,sBACAC,yBAAA,yBACAC,qBAAA,qBACAC,oBAAA,oBACAC,4BAAA,2BAGAC,qBAAA,wBC7DAC,EAAAhP,OAAAiJ,QAEAgG,MAAA,QACAC,SAAA,WACAC,aAAA,eACApC,MAAA,QACAI,oBAAA,sBACAF,gBAAA,kBACAC,gBAAA,kBAEAkC,OAAA,SACAC,OAAA,SACA7B,OAAA,SACAU,iBAAA,mBACAoB,oBAAA,sBACAC,UAAA,YACAC,MAAA,QACAlC,KAAA,OACAmC,WAAA,aACAC,aAAA,eACAC,uBAAA,2BCLA,SAAAC,EAAArO,EAAA0G,GACA,IAAA4H,EAAA,iBAAAtO,EAAA,IAAA0B,EAAA1B,KACA,KAAAsO,aAAA5M,GACA,UAAAK,UAAA,kCAAAiH,OAAAsF,IAGA,OA0DA,SAAA3E,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAuH,GAAA5E,EAAA9C,EAAAC,KACA,IAAArH,KACA,GACAA,EAAAc,KAAAiO,EAAA7E,WACG8E,GAAA9E,EAAA9C,EAAAS,MAEH,OACAlJ,KAAA8M,EAAAC,SACA1L,cACAV,IAAA2P,GAAA/E,EAAAxJ,IArEAwO,CADAlI,EAAA6H,EAAA5H,QAcA,SAAAkI,EAAA5O,EAAA0G,GACA,IACAiD,EAAAlD,EADA,iBAAAzG,EAAA,IAAA0B,EAAA1B,KACA0G,OACA6H,GAAA5E,EAAA9C,EAAAC,KACA,IAAA3H,EAAA0P,EAAAlF,GAAA,GAEA,OADA4E,GAAA5E,EAAA9C,EAAAS,KACAnI,EAaA,SAAA2P,EAAA9O,EAAA0G,GACA,IACAiD,EAAAlD,EADA,iBAAAzG,EAAA,IAAA0B,EAAA1B,KACA0G,OACA6H,GAAA5E,EAAA9C,EAAAC,KACA,IAAAiI,EAAAC,EAAArF,GAEA,OADA4E,GAAA5E,EAAA9C,EAAAS,KACAyH,EAMA,SAAAE,EAAAtF,GACA,IAAA3C,EAAAuH,GAAA5E,EAAA9C,EAAA4B,MACA,OACArK,KAAA8M,EAAAzC,KACAtJ,MAAA6H,EAAA7H,MACAJ,IAAA2P,GAAA/E,EAAA3C,IA6BA,SAAAwH,EAAA7E,GACA,GAAAuF,GAAAvF,EAAA9C,EAAA4B,MACA,OAAAkB,EAAA3C,MAAA7H,OACA,YACA,eACA,mBACA,eACA,OAAAgQ,EAAAxF,GACA,aACA,aACA,WACA,gBACA,YACA,WACA,YACA,aACA,gBAEA,OAAAyF,GAAAzF,OAEG,IAAAuF,GAAAvF,EAAA9C,EAAAyB,SACH,OAAA6G,EAAAxF,GACG,GAAA0F,GAAA1F,GAEH,OAAAyF,GAAAzF,GAGA,MAAA2F,GAAA3F,GAQA,SAAAwF,EAAAxF,GACA,GAAAuF,GAAAvF,EAAA9C,EAAA4B,MACA,OAAAkB,EAAA3C,MAAA7H,OACA,YACA,eACA,mBACA,OAAAoQ,EAAA5F,GAEA,eACA,OA0NA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MAKA,GAJAwI,GAAA7F,EAAA,YAIAA,EAAAjD,QAAA3I,8BACA,OACAK,KAAA8M,EAAAU,oBACA9L,KAAA2P,EAAA9F,GACA+F,oBAAAC,EAAAhG,GACAiG,eAAAJ,GAAA7F,EAAA,MAAAkG,EAAAlG,IACAmG,WAAAC,EAAApG,GAAA,GACAqG,aAAAC,EAAAtG,GACA5K,IAAA2P,GAAA/E,EAAAxJ,IAGA,OACA/B,KAAA8M,EAAAU,oBACA9L,KAAA2P,EAAA9F,GACAiG,eAAAJ,GAAA7F,EAAA,MAAAkG,EAAAlG,IACAmG,WAAAC,EAAApG,GAAA,GACAqG,aAAAC,EAAAtG,GACA5K,IAAA2P,GAAA/E,EAAAxJ,IAjPA+P,CAAAvG,QAEG,GAAAuF,GAAAvF,EAAA9C,EAAAyB,SACH,OAAAiH,EAAA5F,GAGA,MAAA2F,GAAA3F,GAUA,SAAA4F,EAAA5F,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACA,GAAAkI,GAAAvF,EAAA9C,EAAAyB,SACA,OACAlK,KAAA8M,EAAAE,qBACA+E,UAAA,QACArQ,UAAAwE,EACAoL,uBACAI,cACAE,aAAAC,EAAAtG,GACA5K,IAAA2P,GAAA/E,EAAAxJ,IAGA,IAAAgQ,EAAAC,EAAAzG,GACA7J,OAAA,EAIA,OAHAoP,GAAAvF,EAAA9C,EAAA4B,QACA3I,EAAAmP,EAAAtF,KAGAvL,KAAA8M,EAAAE,qBACA+E,YACArQ,OACA4P,oBAAAC,EAAAhG,GACAmG,WAAAC,EAAApG,GAAA,GACAqG,aAAAC,EAAAtG,GACA5K,IAAA2P,GAAA/E,EAAAxJ,IAOA,SAAAiQ,EAAAzG,GACA,IAAA0G,EAAA9B,GAAA5E,EAAA9C,EAAA4B,MACA,OAAA4H,EAAAlR,OACA,YACA,cACA,eACA,iBACA,mBACA,qBAGA,MAAAmQ,GAAA3F,EAAA0G,GAMA,SAAAV,EAAAhG,GACA,OAAAuF,GAAAvF,EAAA9C,EAAAiB,SAAAwI,GAAA3G,EAAA9C,EAAAiB,QAAAyI,EAAA1J,EAAAkB,YAMA,SAAAwI,EAAA5G,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACA,OACA5I,KAAA8M,EAAAG,oBACAmF,SAAAC,EAAA9G,GACAoF,MAAAR,GAAA5E,EAAA9C,EAAAoB,OAAA+G,EAAArF,IACA+G,aAAAjC,GAAA9E,EAAA9C,EAAAqB,QAAA2G,EAAAlF,GAAA,QAAArF,EACAvF,IAAA2P,GAAA/E,EAAAxJ,IAOA,SAAAsQ,EAAA9G,GACA,IAAAxJ,EAAAwJ,EAAA3C,MAEA,OADAuH,GAAA5E,EAAA9C,EAAAe,SAEAxJ,KAAA8M,EAAAI,SACAxL,KAAAmP,EAAAtF,GACA5K,IAAA2P,GAAA/E,EAAAxJ,IAOA,SAAA8P,EAAAtG,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACA,OACA5I,KAAA8M,EAAAK,cACAoF,WAAAL,GAAA3G,EAAA9C,EAAAyB,QAAAsI,EAAA/J,EAAA2B,SACAzJ,IAAA2P,GAAA/E,EAAAxJ,IAUA,SAAAyQ,EAAAjH,GACA,OAAAuF,GAAAvF,EAAA9C,EAAAmB,QAwEA,SAAA2B,GACA,IAAAxJ,EAAAwJ,EAAA3C,MAEA,GADAuH,GAAA5E,EAAA9C,EAAAmB,QACAkH,GAAAvF,EAAA9C,EAAA4B,OAAA,OAAAkB,EAAA3C,MAAA7H,MACA,OACAf,KAAA8M,EAAAQ,gBACA5L,KAAA2P,EAAA9F,GACAmG,WAAAC,EAAApG,GAAA,GACA5K,IAAA2P,GAAA/E,EAAAxJ,IAGA,IAAAyP,OAAA,EACA,OAAAjG,EAAA3C,MAAA7H,QACAwK,EAAAzC,UACA0I,EAAAC,EAAAlG,IAEA,OACAvL,KAAA8M,EAAAS,gBACAiE,gBACAE,WAAAC,EAAApG,GAAA,GACAqG,aAAAC,EAAAtG,GACA5K,IAAA2P,GAAA/E,EAAAxJ,IA7FA0Q,CAAAlH,GAQA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MAEA8J,EAAA7B,EAAAtF,GACAoH,OAAA,EACAjR,OAAA,EACA2O,GAAA9E,EAAA9C,EAAAoB,QACA8I,EAAAD,EACAhR,EAAAmP,EAAAtF,IAEA7J,EAAAgR,EAGA,OACA1S,KAAA8M,EAAAM,MACAuF,QACAjR,OACAe,UAAAmQ,EAAArH,GAAA,GACAmG,WAAAC,EAAApG,GAAA,GACAqG,aAAAd,GAAAvF,EAAA9C,EAAAyB,SAAA2H,EAAAtG,QAAArF,EACAvF,IAAA2P,GAAA/E,EAAAxJ,IA5BA8Q,CAAAtH,GAmCA,SAAAqH,EAAArH,EAAAuH,GACA,IAAAC,EAAAD,EAAAE,EAAAC,EACA,OAAAnC,GAAAvF,EAAA9C,EAAAiB,SAAAwI,GAAA3G,EAAA9C,EAAAiB,QAAAqJ,EAAAtK,EAAAkB,YAMA,SAAAsJ,EAAA1H,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACA,OACA5I,KAAA8M,EAAAO,SACA3L,KAAAmP,EAAAtF,GACAxK,OAAAoP,GAAA5E,EAAA9C,EAAAoB,OAAA4G,EAAAlF,GAAA,IACA5K,IAAA2P,GAAA/E,EAAAxJ,IAIA,SAAAiR,EAAAzH,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACA,OACA5I,KAAA8M,EAAAO,SACA3L,KAAAmP,EAAAtF,GACAxK,OAAAoP,GAAA5E,EAAA9C,EAAAoB,OAAAqJ,EAAA3H,IACA5K,IAAA2P,GAAA/E,EAAAxJ,IA0EA,SAAAsP,EAAA9F,GACA,UAAAA,EAAA3C,MAAA7H,MACA,MAAAmQ,GAAA3F,GAEA,OAAAsF,EAAAtF,GAuBA,SAAAkF,EAAAlF,EAAAuH,GACA,IAAAlK,EAAA2C,EAAA3C,MACA,OAAAA,EAAA5I,MACA,KAAAyI,EAAAuB,UACA,OA0EA,SAAAuB,EAAAuH,GACA,IAAA/Q,EAAAwJ,EAAA3C,MACAmK,EAAAD,EAAAI,EAAAC,EACA,OACAnT,KAAA8M,EAAAc,KACAwF,OAoyBA,SAAA7H,EAAA8H,EAAAC,EAAAC,GACApD,GAAA5E,EAAA8H,GACA,IAAA1N,KACA,MAAA0K,GAAA9E,EAAAgI,IACA5N,EAAAxD,KAAAmR,EAAA/H,IAEA,OAAA5F,EA1yBA6N,CAAAjI,EAAA9C,EAAAuB,UAAA+I,EAAAtK,EAAAwB,WACAtJ,IAAA2P,GAAA/E,EAAAxJ,IAhFA0R,CAAAlI,EAAAuH,GACA,KAAArK,EAAAyB,QACA,OAuFA,SAAAqB,EAAAuH,GACA,IAAA/Q,EAAAwJ,EAAA3C,MACAuH,GAAA5E,EAAA9C,EAAAyB,SACA,IAAAwJ,KACA,MAAArD,GAAA9E,EAAA9C,EAAA2B,UACAsJ,EAAAvR,KAAAwR,EAAApI,EAAAuH,IAEA,OACA9S,KAAA8M,EAAAe,OACA6F,SACA/S,IAAA2P,GAAA/E,EAAAxJ,IAjGA6R,CAAArI,EAAAuH,GACA,KAAArK,EAAA6B,IAEA,OADAiB,EAAAzC,WAEA9I,KAAA8M,EAAAxC,IACAvJ,MAAA6H,EAAA7H,MACAJ,IAAA2P,GAAA/E,EAAA3C,IAEA,KAAAH,EAAA8B,MAEA,OADAgB,EAAAzC,WAEA9I,KAAA8M,EAAAvC,MACAxJ,MAAA6H,EAAA7H,MACAJ,IAAA2P,GAAA/E,EAAA3C,IAEA,KAAAH,EAAA+B,OACA,KAAA/B,EAAAgC,aACA,OAAAoJ,EAAAtI,GACA,KAAA9C,EAAA4B,KACA,eAAAzB,EAAA7H,OAAA,UAAA6H,EAAA7H,OACAwK,EAAAzC,WAEA9I,KAAA8M,EAAAW,QACA1M,MAAA,SAAA6H,EAAA7H,MACAJ,IAAA2P,GAAA/E,EAAA3C,KAEO,SAAAA,EAAA7H,OACPwK,EAAAzC,WAEA9I,KAAA8M,EAAAY,KACA/M,IAAA2P,GAAA/E,EAAA3C,MAGA2C,EAAAzC,WAEA9I,KAAA8M,EAAAa,KACA5M,MAAA6H,EAAA7H,MACAJ,IAAA2P,GAAA/E,EAAA3C,KAEA,KAAAH,EAAAe,OACA,IAAAsJ,EACA,OAAAT,EAAA9G,GAIA,MAAA2F,GAAA3F,GAGA,SAAAsI,EAAAtI,GACA,IAAA3C,EAAA2C,EAAA3C,MAEA,OADA2C,EAAAzC,WAEA9I,KAAA8M,EAAAtC,OACAzJ,MAAA6H,EAAA7H,MACA+S,MAAAlL,EAAA5I,OAAAyI,EAAAgC,aACA9J,IAAA2P,GAAA/E,EAAA3C,IAIA,SAAAsK,EAAA3H,GACA,OAAAkF,EAAAlF,GAAA,GAGA,SAAA4H,EAAA5H,GACA,OAAAkF,EAAAlF,GAAA,GAwCA,SAAAoI,EAAApI,EAAAuH,GACA,IAAA/Q,EAAAwJ,EAAA3C,MACA,OACA5I,KAAA8M,EAAAgB,aACApM,KAAAmP,EAAAtF,GACAxK,OAAAoP,GAAA5E,EAAA9C,EAAAoB,OAAA4G,EAAAlF,EAAAuH,IACAnS,IAAA2P,GAAA/E,EAAAxJ,IASA,SAAA4P,EAAApG,EAAAuH,GAEA,IADA,IAAApB,KACAZ,GAAAvF,EAAA9C,EAAAsB,KACA2H,EAAAvP,KAAA4R,EAAAxI,EAAAuH,IAEA,OAAApB,EAMA,SAAAqC,EAAAxI,EAAAuH,GACA,IAAA/Q,EAAAwJ,EAAA3C,MAEA,OADAuH,GAAA5E,EAAA9C,EAAAsB,KAEA/J,KAAA8M,EAAAiB,UACArM,KAAAmP,EAAAtF,GACA9I,UAAAmQ,EAAArH,EAAAuH,GACAnS,IAAA2P,GAAA/E,EAAAxJ,IAYA,SAAA6O,EAAArF,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACA+H,OAAA,EAYA,OAXAN,GAAA9E,EAAA9C,EAAAuB,YACA2G,EAAAC,EAAArF,GACA4E,GAAA5E,EAAA9C,EAAAwB,WACA0G,GACA3Q,KAAA8M,EAAAmB,UACA0C,OACAhQ,IAAA2P,GAAA/E,EAAAxJ,KAGA4O,EAAAc,EAAAlG,GAEA8E,GAAA9E,EAAA9C,EAAAc,OAEAvJ,KAAA8M,EAAAoB,cACAyC,OACAhQ,IAAA2P,GAAA/E,EAAAxJ,IAGA4O,EAMA,SAAAc,EAAAlG,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACA,OACA5I,KAAA8M,EAAAkB,WACAtM,KAAAmP,EAAAtF,GACA5K,IAAA2P,GAAA/E,EAAAxJ,IAqBA,SAAAiP,GAAAzF,GAEA,IAAAyI,EAAA/C,GAAA1F,KAAAvC,YAAAuC,EAAA3C,MAEA,GAAAoL,EAAAhU,OAAAyI,EAAA4B,KACA,OAAA2J,EAAAjT,OACA,aACA,OAuCA,SAAAwK,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAwI,GAAA7F,EAAA,UACA,IAAAmG,EAAAC,EAAApG,GAAA,GACA0I,EAAA/B,GAAA3G,EAAA9C,EAAAyB,QAAAgK,GAAAzL,EAAA2B,SACA,OACApK,KAAA8M,EAAAqB,kBACAuD,aACAuC,iBACAtT,IAAA2P,GAAA/E,EAAAxJ,IAhDAoS,CAAA5I,GACA,aACA,OAqEA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA6F,GAAA7F,EAAA,UACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACA,OACAvL,KAAA8M,EAAAuB,uBACAlH,cACAzF,OACAgQ,aACA/Q,IAAA2P,GAAA/E,EAAAxJ,IAhFAsS,CAAA9I,GACA,WACA,OAuFA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA6F,GAAA7F,EAAA,QACA,IAAA7J,EAAAmP,EAAAtF,GACA+I,EAAAC,GAAAhJ,GACAmG,EAAAC,EAAApG,GAAA,GACAmI,EAAAc,GAAAjJ,GACA,OACAvL,KAAA8M,EAAAwB,uBACAnH,cACAzF,OACA4S,aACA5C,aACAgC,SACA/S,IAAA2P,GAAA/E,EAAAxJ,IAtGA0S,CAAAlJ,GACA,gBACA,OAwMA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA6F,GAAA7F,EAAA,aACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACAmI,EAAAc,GAAAjJ,GACA,OACAvL,KAAA8M,EAAA2B,0BACAtH,cACAzF,OACAgQ,aACAgC,SACA/S,IAAA2P,GAAA/E,EAAAxJ,IArNA2S,CAAAnJ,GACA,YACA,OA2NA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA6F,GAAA7F,EAAA,SACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACAoJ,EAAAC,GAAArJ,GACA,OACAvL,KAAA8M,EAAA4B,sBACAvH,cACAzF,OACAgQ,aACAiD,QACAhU,IAAA2P,GAAA/E,EAAAxJ,IAxOA8S,CAAAtJ,GACA,WACA,OA+PA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA6F,GAAA7F,EAAA,QACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACA6H,EAAA0B,GAAAvJ,GACA,OACAvL,KAAA8M,EAAA6B,qBACAxH,cACAzF,OACAgQ,aACA0B,SACAzS,IAAA2P,GAAA/E,EAAAxJ,IA5QAgT,CAAAxJ,GACA,YACA,OA4SA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA6F,GAAA7F,EAAA,SACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACAmI,EAAAsB,GAAAzJ,GACA,OACAvL,KAAA8M,EAAA+B,6BACA1H,cACAzF,OACAgQ,aACAgC,SACA/S,IAAA2P,GAAA/E,EAAAxJ,IAzTAkT,CAAA1J,GACA,aACA,OA2UA,SAAAA,GACA,IAAAyI,EAAAzI,EAAAvC,YAEA,GAAAgL,EAAAhU,OAAAyI,EAAA4B,KACA,OAAA2J,EAAAjT,OACA,aACA,OAqBA,SAAAwK,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAwI,GAAA7F,EAAA,UACA6F,GAAA7F,EAAA,UACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACA,OAAAmG,EAAAnQ,OACA,MAAA2P,GAAA3F,GAEA,OACAvL,KAAA8M,EAAAgC,sBACApN,OACAgQ,aACA/Q,IAAA2P,GAAA/E,EAAAxJ,IAlCAmT,CAAA3J,GACA,WACA,OA0CA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAwI,GAAA7F,EAAA,UACA6F,GAAA7F,EAAA,QACA,IAAA7J,EAAAmP,EAAAtF,GACA+I,EAAAC,GAAAhJ,GACAmG,EAAAC,EAAApG,GAAA,GACAmI,EAAAc,GAAAjJ,GACA,OAAA+I,EAAA/S,QAAA,IAAAmQ,EAAAnQ,QAAA,IAAAmS,EAAAnS,OACA,MAAA2P,GAAA3F,GAEA,OACAvL,KAAA8M,EAAAiC,sBACArN,OACA4S,aACA5C,aACAgC,SACA/S,IAAA2P,GAAA/E,EAAAxJ,IA3DAoT,CAAA5J,GACA,gBACA,OAkEA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAwI,GAAA7F,EAAA,UACA6F,GAAA7F,EAAA,aACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACAmI,EAAAc,GAAAjJ,GACA,OAAAmG,EAAAnQ,QAAA,IAAAmS,EAAAnS,OACA,MAAA2P,GAAA3F,GAEA,OACAvL,KAAA8M,EAAAkC,yBACAtN,OACAgQ,aACAgC,SACA/S,IAAA2P,GAAA/E,EAAAxJ,IAjFAqT,CAAA7J,GACA,YACA,OAwFA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAwI,GAAA7F,EAAA,UACA6F,GAAA7F,EAAA,SACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACAoJ,EAAAC,GAAArJ,GACA,OAAAmG,EAAAnQ,QAAA,IAAAoT,EAAApT,OACA,MAAA2P,GAAA3F,GAEA,OACAvL,KAAA8M,EAAAmC,qBACAvN,OACAgQ,aACAiD,QACAhU,IAAA2P,GAAA/E,EAAAxJ,IAvGAsT,CAAA9J,GACA,WACA,OA8GA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAwI,GAAA7F,EAAA,UACA6F,GAAA7F,EAAA,QACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACA6H,EAAA0B,GAAAvJ,GACA,OAAAmG,EAAAnQ,QAAA,IAAA6R,EAAA7R,OACA,MAAA2P,GAAA3F,GAEA,OACAvL,KAAA8M,EAAAoC,oBACAxN,OACAgQ,aACA0B,SACAzS,IAAA2P,GAAA/E,EAAAxJ,IA7HAuT,CAAA/J,GACA,YACA,OAoIA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAwI,GAAA7F,EAAA,UACA6F,GAAA7F,EAAA,SACA,IAAA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACAmI,EAAAsB,GAAAzJ,GACA,OAAAmG,EAAAnQ,QAAA,IAAAmS,EAAAnS,OACA,MAAA2P,GAAA3F,GAEA,OACAvL,KAAA8M,EAAAqC,4BACAzN,OACAgQ,aACAgC,SACA/S,IAAA2P,GAAA/E,EAAAxJ,IAnJAwT,CAAAhK,GAIA,MAAA2F,GAAA3F,EAAAyI,GA/VAwB,CAAAjK,GACA,gBACA,OAofA,SAAAA,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA6F,GAAA7F,EAAA,aACA4E,GAAA5E,EAAA9C,EAAAsB,IACA,IAAArI,EAAAmP,EAAAtF,GACAjJ,EAAAmT,GAAAlK,GACA6F,GAAA7F,EAAA,MACA,IAAA1E,EAgBA,SAAA0E,GAEA8E,GAAA9E,EAAA9C,EAAA0B,MACA,IAAAtD,KACA,GACAA,EAAA1E,KAAAuT,GAAAnK,UACG8E,GAAA9E,EAAA9C,EAAA0B,OACH,OAAAtD,EAvBA8O,CAAApK,GACA,OACAvL,KAAA8M,EAAAsC,qBACAjI,cACAzF,OACAe,UAAAH,EACAuE,YACAlG,IAAA2P,GAAA/E,EAAAxJ,IAngBA6T,CAAArK,GAIA,MAAA2F,GAAA3F,EAAAyI,GAGA,SAAA/C,GAAA1F,GACA,OAAAuF,GAAAvF,EAAA9C,EAAA+B,SAAAsG,GAAAvF,EAAA9C,EAAAgC,cAMA,SAAA2J,GAAA7I,GACA,GAAA0F,GAAA1F,GACA,OAAAsI,EAAAtI,GAuBA,SAAA2I,GAAA3I,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAmJ,EAAAC,EAAAzG,GACA4E,GAAA5E,EAAA9C,EAAAoB,OACA,IAAA8G,EAAAc,EAAAlG,GACA,OACAvL,KAAA8M,EAAAsB,0BACA2D,YACApB,OACAhQ,IAAA2P,GAAA/E,EAAAxJ,IAmDA,SAAAwS,GAAAhJ,GACA,IAAAoJ,KACA,kBAAApJ,EAAA3C,MAAA7H,MAAA,CACAwK,EAAAzC,UAEAuH,GAAA9E,EAAA9C,EAAAgB,KACA,GACAkL,EAAAxS,KAAAsP,EAAAlG,UACK8E,GAAA9E,EAAA9C,EAAAgB,MAEL8B,EAAAjD,QAAAuN,oCAAA/E,GAAAvF,EAAA9C,EAAA4B,OAEA,OAAAsK,EAMA,SAAAH,GAAAjJ,GAEA,OAAAA,EAAAjD,QAAAwN,2BAAAhF,GAAAvF,EAAA9C,EAAAyB,UAAAqB,EAAAvC,YAAAhJ,OAAAyI,EAAA2B,SACAmB,EAAAzC,UACAyC,EAAAzC,cAGAgI,GAAAvF,EAAA9C,EAAAyB,SAAAgI,GAAA3G,EAAA9C,EAAAyB,QAAA6L,GAAAtN,EAAA2B,YAOA,SAAA2L,GAAAxK,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA7J,EAAAmP,EAAAtF,GACAjJ,EAAAmT,GAAAlK,GACA4E,GAAA5E,EAAA9C,EAAAoB,OACA,IAAA8G,EAAAC,EAAArF,GACAmG,EAAAC,EAAApG,GAAA,GACA,OACAvL,KAAA8M,EAAAyB,iBACApH,cACAzF,OACAe,UAAAH,EACAqO,OACAe,aACA/Q,IAAA2P,GAAA/E,EAAAxJ,IAOA,SAAA0T,GAAAlK,GACA,OAAAuF,GAAAvF,EAAA9C,EAAAiB,SAGAwI,GAAA3G,EAAA9C,EAAAiB,QAAAsM,GAAAvN,EAAAkB,YAOA,SAAAqM,GAAAzK,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA7J,EAAAmP,EAAAtF,GACA4E,GAAA5E,EAAA9C,EAAAoB,OACA,IAAA8G,EAAAC,EAAArF,GACA+G,OAAA,EACAjC,GAAA9E,EAAA9C,EAAAqB,UACAwI,EAAAY,EAAA3H,IAEA,IAAAmG,EAAAC,EAAApG,GAAA,GACA,OACAvL,KAAA8M,EAAA0B,uBACArH,cACAzF,OACAiP,OACA2B,eACAZ,aACA/Q,IAAA2P,GAAA/E,EAAAxJ,IAmDA,SAAA6S,GAAArJ,GACA,IAAAoJ,KACA,GAAAtE,GAAA9E,EAAA9C,EAAAqB,QAAA,CAEAuG,GAAA9E,EAAA9C,EAAA0B,MACA,GACAwK,EAAAxS,KAAAsP,EAAAlG,UACK8E,GAAA9E,EAAA9C,EAAA0B,OAEL,OAAAwK,EA2BA,SAAAG,GAAAvJ,GACA,OAAAuF,GAAAvF,EAAA9C,EAAAyB,SAAAgI,GAAA3G,EAAA9C,EAAAyB,QAAA+L,GAAAxN,EAAA2B,YAQA,SAAA6L,GAAA1K,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAzB,EAAAiN,GAAA7I,GACA7J,EAAAmP,EAAAtF,GACAmG,EAAAC,EAAApG,GAAA,GACA,OACAvL,KAAA8M,EAAA8B,sBACAzH,cACAzF,OACAgQ,aACA/Q,IAAA2P,GAAA/E,EAAAxJ,IA4BA,SAAAiT,GAAAzJ,GACA,OAAAuF,GAAAvF,EAAA9C,EAAAyB,SAAAgI,GAAA3G,EAAA9C,EAAAyB,QAAA8L,GAAAvN,EAAA2B,YAoPA,SAAAsL,GAAAnK,GACA,IAAAxJ,EAAAwJ,EAAA3C,MACAlH,EAAAmP,EAAAtF,GACA,GAAA8D,EAAAnO,eAAAQ,EAAAX,OACA,OAAAW,EAEA,MAAAwP,GAAA3F,EAAAxJ,GASA,SAAAuO,GAAA/E,EAAA3K,GACA,IAAA2K,EAAAjD,QAAA4N,WACA,WAAAC,GAAAvV,EAAA2K,EAAA5C,UAAA4C,EAAA3J,QAIA,SAAAuU,GAAAvV,EAAAC,EAAAe,GACAiC,KAAA9B,MAAAnB,EAAAmB,MACA8B,KAAA7B,IAAAnB,EAAAmB,IACA6B,KAAAjD,aACAiD,KAAAhD,WACAgD,KAAAjC,SAWA,SAAAkP,GAAAvF,EAAAvL,GACA,OAAAuL,EAAA3C,MAAA5I,SAOA,SAAAqQ,GAAA9E,EAAAvL,GACA,IAAAmE,EAAAoH,EAAA3C,MAAA5I,SAIA,OAHAmE,GACAoH,EAAAzC,UAEA3E,EAOA,SAAAgM,GAAA5E,EAAAvL,GACA,IAAA4I,EAAA2C,EAAA3C,MACA,GAAAA,EAAA5I,SAEA,OADAuL,EAAAzC,UACAF,EAEA,MAAA1B,EAAAqE,EAAA3J,OAAAgH,EAAA7G,MAAA,YAAA/B,EAAA,WAAA0K,EAAA9B,IAQA,SAAAwI,GAAA7F,EAAAxK,GACA,IAAA6H,EAAA2C,EAAA3C,MACA,GAAAA,EAAA5I,OAAAyI,EAAA4B,MAAAzB,EAAA7H,UAEA,OADAwK,EAAAzC,UACAF,EAEA,MAAA1B,EAAAqE,EAAA3J,OAAAgH,EAAA7G,MAAA,aAAAhB,EAAA,YAAA2J,EAAA9B,IAOA,SAAAsI,GAAA3F,EAAA6K,GACA,IAAAxN,EAAAwN,GAAA7K,EAAA3C,MACA,OAAA1B,EAAAqE,EAAA3J,OAAAgH,EAAA7G,MAAA,cAAA2I,EAAA9B,IAwBA,SAAAsJ,GAAA3G,EAAA8H,EAAAC,EAAAC,GACApD,GAAA5E,EAAA8H,GAEA,IADA,IAAA1N,GAAA2N,EAAA/H,KACA8E,GAAA9E,EAAAgI,IACA5N,EAAAxD,KAAAmR,EAAA/H,IAEA,OAAA5F,sNA1zCAxG,EAAAuB,EAAA2V,EAAA,mCAAA5E,IAouCA0E,GAAA7V,UAAAsM,OAAAuJ,GAAA7V,UAAAuM,QAAA,WACA,OAAU9K,MAAA8B,KAAA9B,MAAAC,IAAA6B,KAAA7B","file":"vendors~admin~graphql-tag.402ca898.chunk.js","sourcesContent":["var parser = require('graphql/language/parser');\n\nvar parse = parser.parse;\n\n// Strip insignificant whitespace\n// Note that this could do a lot more, such as reorder fields etc.\nfunction normalize(string) {\n  return string.replace(/[\\s,]+/g, ' ').trim();\n}\n\n// A map docString -> graphql document\nvar docCache = {};\n\n// A map fragmentName -> [normalized source]\nvar fragmentSourceMap = {};\n\nfunction cacheKeyFromLoc(loc) {\n  return normalize(loc.source.body.substring(loc.start, loc.end));\n}\n\n// For testing.\nfunction resetCaches() {\n  docCache = {};\n  fragmentSourceMap = {};\n}\n\n// Take a unstripped parsed document (query/mutation or even fragment), and\n// check all fragment definitions, checking for name->source uniqueness.\n// We also want to make sure only unique fragments exist in the document.\nvar printFragmentWarnings = true;\nfunction processFragments(ast) {\n  var astFragmentMap = {};\n  var definitions = [];\n\n  for (var i = 0; i < ast.definitions.length; i++) {\n    var fragmentDefinition = ast.definitions[i];\n\n    if (fragmentDefinition.kind === 'FragmentDefinition') {\n      var fragmentName = fragmentDefinition.name.value;\n      var sourceKey = cacheKeyFromLoc(fragmentDefinition.loc);\n\n      // We know something about this fragment\n      if (fragmentSourceMap.hasOwnProperty(fragmentName) && !fragmentSourceMap[fragmentName][sourceKey]) {\n\n        // this is a problem because the app developer is trying to register another fragment with\n        // the same name as one previously registered. So, we tell them about it.\n        if (printFragmentWarnings) {\n          console.warn(\"Warning: fragment with name \" + fragmentName + \" already exists.\\n\"\n            + \"graphql-tag enforces all fragment names across your application to be unique; read more about\\n\"\n            + \"this in the docs: http://dev.apollodata.com/core/fragments.html#unique-names\");\n        }\n\n        fragmentSourceMap[fragmentName][sourceKey] = true;\n\n      } else if (!fragmentSourceMap.hasOwnProperty(fragmentName)) {\n        fragmentSourceMap[fragmentName] = {};\n        fragmentSourceMap[fragmentName][sourceKey] = true;\n      }\n\n      if (!astFragmentMap[sourceKey]) {\n        astFragmentMap[sourceKey] = true;\n        definitions.push(fragmentDefinition);\n      }\n    } else {\n      definitions.push(fragmentDefinition);\n    }\n  }\n\n  ast.definitions = definitions;\n  return ast;\n}\n\nfunction disableFragmentWarnings() {\n  printFragmentWarnings = false;\n}\n\nfunction stripLoc(doc, removeLocAtThisLevel) {\n  var docType = Object.prototype.toString.call(doc);\n\n  if (docType === '[object Array]') {\n    return doc.map(function (d) {\n      return stripLoc(d, removeLocAtThisLevel);\n    });\n  }\n\n  if (docType !== '[object Object]') {\n    throw new Error('Unexpected input.');\n  }\n\n  // We don't want to remove the root loc field so we can use it\n  // for fragment substitution (see below)\n  if (removeLocAtThisLevel && doc.loc) {\n    delete doc.loc;\n  }\n\n  // https://github.com/apollographql/graphql-tag/issues/40\n  if (doc.loc) {\n    delete doc.loc.startToken;\n    delete doc.loc.endToken;\n  }\n\n  var keys = Object.keys(doc);\n  var key;\n  var value;\n  var valueType;\n\n  for (key in keys) {\n    if (keys.hasOwnProperty(key)) {\n      value = doc[keys[key]];\n      valueType = Object.prototype.toString.call(value);\n\n      if (valueType === '[object Object]' || valueType === '[object Array]') {\n        doc[keys[key]] = stripLoc(value, true);\n      }\n    }\n  }\n\n  return doc;\n}\n\nvar experimentalFragmentVariables = false;\nfunction parseDocument(doc) {\n  var cacheKey = normalize(doc);\n\n  if (docCache[cacheKey]) {\n    return docCache[cacheKey];\n  }\n\n  var parsed = parse(doc, { experimentalFragmentVariables: experimentalFragmentVariables });\n  if (!parsed || parsed.kind !== 'Document') {\n    throw new Error('Not a valid GraphQL document.');\n  }\n\n  // check that all \"new\" fragments inside the documents are consistent with\n  // existing fragments of the same name\n  parsed = processFragments(parsed);\n  parsed = stripLoc(parsed, false);\n  docCache[cacheKey] = parsed;\n\n  return parsed;\n}\n\nfunction enableExperimentalFragmentVariables() {\n  experimentalFragmentVariables = true;\n}\n\nfunction disableExperimentalFragmentVariables() {\n  experimentalFragmentVariables = false;\n}\n\n// XXX This should eventually disallow arbitrary string interpolation, like Relay does\nfunction gql(/* arguments */) {\n  var args = Array.prototype.slice.call(arguments);\n\n  var literals = args[0];\n\n  // We always get literals[0] and then matching post literals for each arg given\n  var result = (typeof(literals) === \"string\") ? literals : literals[0];\n\n  for (var i = 1; i < args.length; i++) {\n    if (args[i] && args[i].kind && args[i].kind === 'Document') {\n      result += args[i].loc.source.body;\n    } else {\n      result += args[i];\n    }\n\n    result += literals[i];\n  }\n\n  return parseDocument(result);\n}\n\n// Support typescript, which isn't as nice as Babel about default exports\ngql.default = gql;\ngql.resetCaches = resetCaches;\ngql.disableFragmentWarnings = disableFragmentWarnings;\ngql.enableExperimentalFragmentVariables = enableExperimentalFragmentVariables;\ngql.disableExperimentalFragmentVariables = disableExperimentalFragmentVariables;\n\nmodule.exports = gql;\n","/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nexport default function invariant(condition, message) {\n  /* istanbul ignore else */\n  if (!condition) {\n    throw new Error(message);\n  }\n}","function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nimport invariant from '../jsutils/invariant';\n\n/**\n * A representation of source input to GraphQL.\n * `name` and `locationOffset` are optional. They are useful for clients who\n * store GraphQL documents in source files; for example, if the GraphQL input\n * starts at line 40 in a file named Foo.graphql, it might be useful for name to\n * be \"Foo.graphql\" and location to be `{ line: 40, column: 0 }`.\n * line and column in locationOffset are 1-indexed\n */\nexport var Source = function Source(body, name, locationOffset) {\n  _classCallCheck(this, Source);\n\n  this.body = body;\n  this.name = name || 'GraphQL request';\n  this.locationOffset = locationOffset || { line: 1, column: 1 };\n  !(this.locationOffset.line > 0) ? invariant(0, 'line in locationOffset is 1-indexed and must be positive') : void 0;\n  !(this.locationOffset.column > 0) ? invariant(0, 'column in locationOffset is 1-indexed and must be positive') : void 0;\n};","\n\n/**\n * Takes a Source and a UTF-8 character offset, and returns the corresponding\n * line and column as a SourceLocation.\n */\n/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nexport function getLocation(source, position) {\n  var lineRegexp = /\\r\\n|[\\n\\r]/g;\n  var line = 1;\n  var column = position + 1;\n  var match = void 0;\n  while ((match = lineRegexp.exec(source.body)) && match.index < position) {\n    line += 1;\n    column = position + 1 - (match.index + match[0].length);\n  }\n  return { line: line, column: column };\n}\n\n/**\n * Represents a location in a Source.\n */","/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nimport { getLocation } from '../language/location';\n\n\n/**\n * Prints a GraphQLError to a string, representing useful location information\n * about the error's position in the source.\n */\nexport function printError(error) {\n  var printedLocations = [];\n  if (error.nodes) {\n    error.nodes.forEach(function (node) {\n      if (node.loc) {\n        printedLocations.push(highlightSourceAtLocation(node.loc.source, getLocation(node.loc.source, node.loc.start)));\n      }\n    });\n  } else if (error.source && error.locations) {\n    var source = error.source;\n    error.locations.forEach(function (location) {\n      printedLocations.push(highlightSourceAtLocation(source, location));\n    });\n  }\n  return printedLocations.length === 0 ? error.message : [error.message].concat(printedLocations).join('\\n\\n') + '\\n';\n}\n\n/**\n * Render a helpful description of the location of the error in the GraphQL\n * Source document.\n */\nfunction highlightSourceAtLocation(source, location) {\n  var line = location.line;\n  var lineOffset = source.locationOffset.line - 1;\n  var columnOffset = getColumnOffset(source, location);\n  var contextLine = line + lineOffset;\n  var contextColumn = location.column + columnOffset;\n  var prevLineNum = (contextLine - 1).toString();\n  var lineNum = contextLine.toString();\n  var nextLineNum = (contextLine + 1).toString();\n  var padLen = nextLineNum.length;\n  var lines = source.body.split(/\\r\\n|[\\n\\r]/g);\n  lines[0] = whitespace(source.locationOffset.column - 1) + lines[0];\n  var outputLines = [source.name + ' (' + contextLine + ':' + contextColumn + ')', line >= 2 && lpad(padLen, prevLineNum) + ': ' + lines[line - 2], lpad(padLen, lineNum) + ': ' + lines[line - 1], whitespace(2 + padLen + contextColumn - 1) + '^', line < lines.length && lpad(padLen, nextLineNum) + ': ' + lines[line]];\n  return outputLines.filter(Boolean).join('\\n');\n}\n\nfunction getColumnOffset(source, location) {\n  return location.line === 1 ? source.locationOffset.column - 1 : 0;\n}\n\nfunction whitespace(len) {\n  return Array(len + 1).join(' ');\n}\n\nfunction lpad(len, str) {\n  return whitespace(len - str.length) + str;\n}","/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nimport { printError } from './printError';\nimport { getLocation } from '../language/location';\n\n/**\n * A GraphQLError describes an Error found during the parse, validate, or\n * execute phases of performing a GraphQL operation. In addition to a message\n * and stack trace, it also includes information about the locations in a\n * GraphQL document and/or execution result that correspond to the Error.\n */\n\n\nexport function GraphQLError( // eslint-disable-line no-redeclare\nmessage, nodes, source, positions, path, originalError, extensions) {\n  // Compute list of blame nodes.\n  var _nodes = Array.isArray(nodes) ? nodes.length !== 0 ? nodes : undefined : nodes ? [nodes] : undefined;\n\n  // Compute locations in the source for the given nodes/positions.\n  var _source = source;\n  if (!_source && _nodes) {\n    var node = _nodes[0];\n    _source = node && node.loc && node.loc.source;\n  }\n\n  var _positions = positions;\n  if (!_positions && _nodes) {\n    _positions = _nodes.reduce(function (list, node) {\n      if (node.loc) {\n        list.push(node.loc.start);\n      }\n      return list;\n    }, []);\n  }\n  if (_positions && _positions.length === 0) {\n    _positions = undefined;\n  }\n\n  var _locations = void 0;\n  if (positions && source) {\n    _locations = positions.map(function (pos) {\n      return getLocation(source, pos);\n    });\n  } else if (_nodes) {\n    _locations = _nodes.reduce(function (list, node) {\n      if (node.loc) {\n        list.push(getLocation(node.loc.source, node.loc.start));\n      }\n      return list;\n    }, []);\n  }\n\n  Object.defineProperties(this, {\n    message: {\n      value: message,\n      // By being enumerable, JSON.stringify will include `message` in the\n      // resulting output. This ensures that the simplest possible GraphQL\n      // service adheres to the spec.\n      enumerable: true,\n      writable: true\n    },\n    locations: {\n      // Coercing falsey values to undefined ensures they will not be included\n      // in JSON.stringify() when not provided.\n      value: _locations || undefined,\n      // By being enumerable, JSON.stringify will include `locations` in the\n      // resulting output. This ensures that the simplest possible GraphQL\n      // service adheres to the spec.\n      enumerable: true\n    },\n    path: {\n      // Coercing falsey values to undefined ensures they will not be included\n      // in JSON.stringify() when not provided.\n      value: path || undefined,\n      // By being enumerable, JSON.stringify will include `path` in the\n      // resulting output. This ensures that the simplest possible GraphQL\n      // service adheres to the spec.\n      enumerable: true\n    },\n    nodes: {\n      value: _nodes || undefined\n    },\n    source: {\n      value: _source || undefined\n    },\n    positions: {\n      value: _positions || undefined\n    },\n    originalError: {\n      value: originalError\n    },\n    extensions: {\n      value: extensions || originalError && originalError.extensions\n    }\n  });\n\n  // Include (non-enumerable) stack trace.\n  if (originalError && originalError.stack) {\n    Object.defineProperty(this, 'stack', {\n      value: originalError.stack,\n      writable: true,\n      configurable: true\n    });\n  } else if (Error.captureStackTrace) {\n    Error.captureStackTrace(this, GraphQLError);\n  } else {\n    Object.defineProperty(this, 'stack', {\n      value: Error().stack,\n      writable: true,\n      configurable: true\n    });\n  }\n}\n\nGraphQLError.prototype = Object.create(Error.prototype, {\n  constructor: { value: GraphQLError },\n  name: { value: 'GraphQLError' },\n  toString: {\n    value: function toString() {\n      return printError(this);\n    }\n  }\n});","\nimport { GraphQLError } from './GraphQLError';\n\n/**\n * Produces a GraphQLError representing a syntax error, containing useful\n * descriptive information about the syntax error's position in the source.\n */\n/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nexport function syntaxError(source, position, description) {\n  return new GraphQLError('Syntax Error: ' + description, undefined, source, [position]);\n}","var _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; };\n\n/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nimport invariant from '../jsutils/invariant';\n\n\n/**\n * Given a GraphQLError, format it according to the rules described by the\n * Response Format, Errors section of the GraphQL Specification.\n */\nexport function formatError(error) {\n  !error ? invariant(0, 'Received null or undefined error.') : void 0;\n  return _extends({}, error.extensions, {\n    message: error.message || 'An unknown error occurred.',\n    locations: error.locations,\n    path: error.path\n  });\n}","/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\n/**\n * Produces the value of a block string from its parsed raw value, similar to\n * Coffeescript's block string, Python's docstring trim or Ruby's strip_heredoc.\n *\n * This implements the GraphQL spec's BlockStringValue() static algorithm.\n */\nexport default function blockStringValue(rawString) {\n  // Expand a block string's raw value into independent lines.\n  var lines = rawString.split(/\\r\\n|[\\n\\r]/g);\n\n  // Remove common indentation from all lines but first.\n  var commonIndent = null;\n  for (var i = 1; i < lines.length; i++) {\n    var line = lines[i];\n    var indent = leadingWhitespace(line);\n    if (indent < line.length && (commonIndent === null || indent < commonIndent)) {\n      commonIndent = indent;\n      if (commonIndent === 0) {\n        break;\n      }\n    }\n  }\n\n  if (commonIndent) {\n    for (var _i = 1; _i < lines.length; _i++) {\n      lines[_i] = lines[_i].slice(commonIndent);\n    }\n  }\n\n  // Remove leading and trailing blank lines.\n  while (lines.length > 0 && isBlank(lines[0])) {\n    lines.shift();\n  }\n  while (lines.length > 0 && isBlank(lines[lines.length - 1])) {\n    lines.pop();\n  }\n\n  // Return a string of the lines joined with U+000A.\n  return lines.join('\\n');\n}\n\nfunction leadingWhitespace(str) {\n  var i = 0;\n  while (i < str.length && (str[i] === ' ' || str[i] === '\\t')) {\n    i++;\n  }\n  return i;\n}\n\nfunction isBlank(str) {\n  return leadingWhitespace(str) === str.length;\n}","/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nimport { syntaxError } from '../error';\nimport blockStringValue from './blockStringValue';\n\n/**\n * Given a Source object, this returns a Lexer for that source.\n * A Lexer is a stateful stream generator in that every time\n * it is advanced, it returns the next token in the Source. Assuming the\n * source lexes, the final Token emitted by the lexer will be of kind\n * EOF, after which the lexer will repeatedly return the same EOF token\n * whenever called.\n */\nexport function createLexer(source, options) {\n  var startOfFileToken = new Tok(TokenKind.SOF, 0, 0, 0, 0, null);\n  var lexer = {\n    source: source,\n    options: options,\n    lastToken: startOfFileToken,\n    token: startOfFileToken,\n    line: 1,\n    lineStart: 0,\n    advance: advanceLexer,\n    lookahead: lookahead\n  };\n  return lexer;\n}\n\nfunction advanceLexer() {\n  this.lastToken = this.token;\n  var token = this.token = this.lookahead();\n  return token;\n}\n\nfunction lookahead() {\n  var token = this.token;\n  if (token.kind !== TokenKind.EOF) {\n    do {\n      // Note: next is only mutable during parsing, so we cast to allow this.\n      token = token.next || (token.next = readToken(this, token));\n    } while (token.kind === TokenKind.COMMENT);\n  }\n  return token;\n}\n\n/**\n * The return type of createLexer.\n */\n\n\n/**\n * An exported enum describing the different kinds of tokens that the\n * lexer emits.\n */\nexport var TokenKind = Object.freeze({\n  SOF: '<SOF>',\n  EOF: '<EOF>',\n  BANG: '!',\n  DOLLAR: '$',\n  AMP: '&',\n  PAREN_L: '(',\n  PAREN_R: ')',\n  SPREAD: '...',\n  COLON: ':',\n  EQUALS: '=',\n  AT: '@',\n  BRACKET_L: '[',\n  BRACKET_R: ']',\n  BRACE_L: '{',\n  PIPE: '|',\n  BRACE_R: '}',\n  NAME: 'Name',\n  INT: 'Int',\n  FLOAT: 'Float',\n  STRING: 'String',\n  BLOCK_STRING: 'BlockString',\n  COMMENT: 'Comment'\n});\n\n/**\n * The enum type representing the token kinds values.\n */\n\n\n/**\n * A helper function to describe a token as a string for debugging\n */\nexport function getTokenDesc(token) {\n  var value = token.value;\n  return value ? token.kind + ' \"' + value + '\"' : token.kind;\n}\n\nvar charCodeAt = String.prototype.charCodeAt;\nvar slice = String.prototype.slice;\n\n/**\n * Helper function for constructing the Token object.\n */\nfunction Tok(kind, start, end, line, column, prev, value) {\n  this.kind = kind;\n  this.start = start;\n  this.end = end;\n  this.line = line;\n  this.column = column;\n  this.value = value;\n  this.prev = prev;\n  this.next = null;\n}\n\n// Print a simplified form when appearing in JSON/util.inspect.\nTok.prototype.toJSON = Tok.prototype.inspect = function toJSON() {\n  return {\n    kind: this.kind,\n    value: this.value,\n    line: this.line,\n    column: this.column\n  };\n};\n\nfunction printCharCode(code) {\n  return (\n    // NaN/undefined represents access beyond the end of the file.\n    isNaN(code) ? TokenKind.EOF : // Trust JSON for ASCII.\n    code < 0x007f ? JSON.stringify(String.fromCharCode(code)) : // Otherwise print the escaped form.\n    '\"\\\\u' + ('00' + code.toString(16).toUpperCase()).slice(-4) + '\"'\n  );\n}\n\n/**\n * Gets the next token from the source starting at the given position.\n *\n * This skips over whitespace and comments until it finds the next lexable\n * token, then lexes punctuators immediately or calls the appropriate helper\n * function for more complicated tokens.\n */\nfunction readToken(lexer, prev) {\n  var source = lexer.source;\n  var body = source.body;\n  var bodyLength = body.length;\n\n  var pos = positionAfterWhitespace(body, prev.end, lexer);\n  var line = lexer.line;\n  var col = 1 + pos - lexer.lineStart;\n\n  if (pos >= bodyLength) {\n    return new Tok(TokenKind.EOF, bodyLength, bodyLength, line, col, prev);\n  }\n\n  var code = charCodeAt.call(body, pos);\n\n  // SourceCharacter\n  if (code < 0x0020 && code !== 0x0009 && code !== 0x000a && code !== 0x000d) {\n    throw syntaxError(source, pos, 'Cannot contain the invalid character ' + printCharCode(code) + '.');\n  }\n\n  switch (code) {\n    // !\n    case 33:\n      return new Tok(TokenKind.BANG, pos, pos + 1, line, col, prev);\n    // #\n    case 35:\n      return readComment(source, pos, line, col, prev);\n    // $\n    case 36:\n      return new Tok(TokenKind.DOLLAR, pos, pos + 1, line, col, prev);\n    // &\n    case 38:\n      return new Tok(TokenKind.AMP, pos, pos + 1, line, col, prev);\n    // (\n    case 40:\n      return new Tok(TokenKind.PAREN_L, pos, pos + 1, line, col, prev);\n    // )\n    case 41:\n      return new Tok(TokenKind.PAREN_R, pos, pos + 1, line, col, prev);\n    // .\n    case 46:\n      if (charCodeAt.call(body, pos + 1) === 46 && charCodeAt.call(body, pos + 2) === 46) {\n        return new Tok(TokenKind.SPREAD, pos, pos + 3, line, col, prev);\n      }\n      break;\n    // :\n    case 58:\n      return new Tok(TokenKind.COLON, pos, pos + 1, line, col, prev);\n    // =\n    case 61:\n      return new Tok(TokenKind.EQUALS, pos, pos + 1, line, col, prev);\n    // @\n    case 64:\n      return new Tok(TokenKind.AT, pos, pos + 1, line, col, prev);\n    // [\n    case 91:\n      return new Tok(TokenKind.BRACKET_L, pos, pos + 1, line, col, prev);\n    // ]\n    case 93:\n      return new Tok(TokenKind.BRACKET_R, pos, pos + 1, line, col, prev);\n    // {\n    case 123:\n      return new Tok(TokenKind.BRACE_L, pos, pos + 1, line, col, prev);\n    // |\n    case 124:\n      return new Tok(TokenKind.PIPE, pos, pos + 1, line, col, prev);\n    // }\n    case 125:\n      return new Tok(TokenKind.BRACE_R, pos, pos + 1, line, col, prev);\n    // A-Z _ a-z\n    case 65:\n    case 66:\n    case 67:\n    case 68:\n    case 69:\n    case 70:\n    case 71:\n    case 72:\n    case 73:\n    case 74:\n    case 75:\n    case 76:\n    case 77:\n    case 78:\n    case 79:\n    case 80:\n    case 81:\n    case 82:\n    case 83:\n    case 84:\n    case 85:\n    case 86:\n    case 87:\n    case 88:\n    case 89:\n    case 90:\n    case 95:\n    case 97:\n    case 98:\n    case 99:\n    case 100:\n    case 101:\n    case 102:\n    case 103:\n    case 104:\n    case 105:\n    case 106:\n    case 107:\n    case 108:\n    case 109:\n    case 110:\n    case 111:\n    case 112:\n    case 113:\n    case 114:\n    case 115:\n    case 116:\n    case 117:\n    case 118:\n    case 119:\n    case 120:\n    case 121:\n    case 122:\n      return readName(source, pos, line, col, prev);\n    // - 0-9\n    case 45:\n    case 48:\n    case 49:\n    case 50:\n    case 51:\n    case 52:\n    case 53:\n    case 54:\n    case 55:\n    case 56:\n    case 57:\n      return readNumber(source, pos, code, line, col, prev);\n    // \"\n    case 34:\n      if (charCodeAt.call(body, pos + 1) === 34 && charCodeAt.call(body, pos + 2) === 34) {\n        return readBlockString(source, pos, line, col, prev);\n      }\n      return readString(source, pos, line, col, prev);\n  }\n\n  throw syntaxError(source, pos, unexpectedCharacterMessage(code));\n}\n\n/**\n * Report a message that an unexpected character was encountered.\n */\nfunction unexpectedCharacterMessage(code) {\n  if (code === 39) {\n    // '\n    return \"Unexpected single quote character ('), did you mean to use \" + 'a double quote (\")?';\n  }\n\n  return 'Cannot parse the unexpected character ' + printCharCode(code) + '.';\n}\n\n/**\n * Reads from body starting at startPosition until it finds a non-whitespace\n * or commented character, then returns the position of that character for\n * lexing.\n */\nfunction positionAfterWhitespace(body, startPosition, lexer) {\n  var bodyLength = body.length;\n  var position = startPosition;\n  while (position < bodyLength) {\n    var code = charCodeAt.call(body, position);\n    // tab | space | comma | BOM\n    if (code === 9 || code === 32 || code === 44 || code === 0xfeff) {\n      ++position;\n    } else if (code === 10) {\n      // new line\n      ++position;\n      ++lexer.line;\n      lexer.lineStart = position;\n    } else if (code === 13) {\n      // carriage return\n      if (charCodeAt.call(body, position + 1) === 10) {\n        position += 2;\n      } else {\n        ++position;\n      }\n      ++lexer.line;\n      lexer.lineStart = position;\n    } else {\n      break;\n    }\n  }\n  return position;\n}\n\n/**\n * Reads a comment token from the source file.\n *\n * #[\\u0009\\u0020-\\uFFFF]*\n */\nfunction readComment(source, start, line, col, prev) {\n  var body = source.body;\n  var code = void 0;\n  var position = start;\n\n  do {\n    code = charCodeAt.call(body, ++position);\n  } while (code !== null && (\n  // SourceCharacter but not LineTerminator\n  code > 0x001f || code === 0x0009));\n\n  return new Tok(TokenKind.COMMENT, start, position, line, col, prev, slice.call(body, start + 1, position));\n}\n\n/**\n * Reads a number token from the source file, either a float\n * or an int depending on whether a decimal point appears.\n *\n * Int:   -?(0|[1-9][0-9]*)\n * Float: -?(0|[1-9][0-9]*)(\\.[0-9]+)?((E|e)(+|-)?[0-9]+)?\n */\nfunction readNumber(source, start, firstCode, line, col, prev) {\n  var body = source.body;\n  var code = firstCode;\n  var position = start;\n  var isFloat = false;\n\n  if (code === 45) {\n    // -\n    code = charCodeAt.call(body, ++position);\n  }\n\n  if (code === 48) {\n    // 0\n    code = charCodeAt.call(body, ++position);\n    if (code >= 48 && code <= 57) {\n      throw syntaxError(source, position, 'Invalid number, unexpected digit after 0: ' + printCharCode(code) + '.');\n    }\n  } else {\n    position = readDigits(source, position, code);\n    code = charCodeAt.call(body, position);\n  }\n\n  if (code === 46) {\n    // .\n    isFloat = true;\n\n    code = charCodeAt.call(body, ++position);\n    position = readDigits(source, position, code);\n    code = charCodeAt.call(body, position);\n  }\n\n  if (code === 69 || code === 101) {\n    // E e\n    isFloat = true;\n\n    code = charCodeAt.call(body, ++position);\n    if (code === 43 || code === 45) {\n      // + -\n      code = charCodeAt.call(body, ++position);\n    }\n    position = readDigits(source, position, code);\n  }\n\n  return new Tok(isFloat ? TokenKind.FLOAT : TokenKind.INT, start, position, line, col, prev, slice.call(body, start, position));\n}\n\n/**\n * Returns the new position in the source after reading digits.\n */\nfunction readDigits(source, start, firstCode) {\n  var body = source.body;\n  var position = start;\n  var code = firstCode;\n  if (code >= 48 && code <= 57) {\n    // 0 - 9\n    do {\n      code = charCodeAt.call(body, ++position);\n    } while (code >= 48 && code <= 57); // 0 - 9\n    return position;\n  }\n  throw syntaxError(source, position, 'Invalid number, expected digit but got: ' + printCharCode(code) + '.');\n}\n\n/**\n * Reads a string token from the source file.\n *\n * \"([^\"\\\\\\u000A\\u000D]|(\\\\(u[0-9a-fA-F]{4}|[\"\\\\/bfnrt])))*\"\n */\nfunction readString(source, start, line, col, prev) {\n  var body = source.body;\n  var position = start + 1;\n  var chunkStart = position;\n  var code = 0;\n  var value = '';\n\n  while (position < body.length && (code = charCodeAt.call(body, position)) !== null &&\n  // not LineTerminator\n  code !== 0x000a && code !== 0x000d) {\n    // Closing Quote (\")\n    if (code === 34) {\n      value += slice.call(body, chunkStart, position);\n      return new Tok(TokenKind.STRING, start, position + 1, line, col, prev, value);\n    }\n\n    // SourceCharacter\n    if (code < 0x0020 && code !== 0x0009) {\n      throw syntaxError(source, position, 'Invalid character within String: ' + printCharCode(code) + '.');\n    }\n\n    ++position;\n    if (code === 92) {\n      // \\\n      value += slice.call(body, chunkStart, position - 1);\n      code = charCodeAt.call(body, position);\n      switch (code) {\n        case 34:\n          value += '\"';\n          break;\n        case 47:\n          value += '/';\n          break;\n        case 92:\n          value += '\\\\';\n          break;\n        case 98:\n          value += '\\b';\n          break;\n        case 102:\n          value += '\\f';\n          break;\n        case 110:\n          value += '\\n';\n          break;\n        case 114:\n          value += '\\r';\n          break;\n        case 116:\n          value += '\\t';\n          break;\n        case 117:\n          // u\n          var charCode = uniCharCode(charCodeAt.call(body, position + 1), charCodeAt.call(body, position + 2), charCodeAt.call(body, position + 3), charCodeAt.call(body, position + 4));\n          if (charCode < 0) {\n            throw syntaxError(source, position, 'Invalid character escape sequence: ' + ('\\\\u' + body.slice(position + 1, position + 5) + '.'));\n          }\n          value += String.fromCharCode(charCode);\n          position += 4;\n          break;\n        default:\n          throw syntaxError(source, position, 'Invalid character escape sequence: \\\\' + String.fromCharCode(code) + '.');\n      }\n      ++position;\n      chunkStart = position;\n    }\n  }\n\n  throw syntaxError(source, position, 'Unterminated string.');\n}\n\n/**\n * Reads a block string token from the source file.\n *\n * \"\"\"(\"?\"?(\\\\\"\"\"|\\\\(?!=\"\"\")|[^\"\\\\]))*\"\"\"\n */\nfunction readBlockString(source, start, line, col, prev) {\n  var body = source.body;\n  var position = start + 3;\n  var chunkStart = position;\n  var code = 0;\n  var rawValue = '';\n\n  while (position < body.length && (code = charCodeAt.call(body, position)) !== null) {\n    // Closing Triple-Quote (\"\"\")\n    if (code === 34 && charCodeAt.call(body, position + 1) === 34 && charCodeAt.call(body, position + 2) === 34) {\n      rawValue += slice.call(body, chunkStart, position);\n      return new Tok(TokenKind.BLOCK_STRING, start, position + 3, line, col, prev, blockStringValue(rawValue));\n    }\n\n    // SourceCharacter\n    if (code < 0x0020 && code !== 0x0009 && code !== 0x000a && code !== 0x000d) {\n      throw syntaxError(source, position, 'Invalid character within String: ' + printCharCode(code) + '.');\n    }\n\n    // Escape Triple-Quote (\\\"\"\")\n    if (code === 92 && charCodeAt.call(body, position + 1) === 34 && charCodeAt.call(body, position + 2) === 34 && charCodeAt.call(body, position + 3) === 34) {\n      rawValue += slice.call(body, chunkStart, position) + '\"\"\"';\n      position += 4;\n      chunkStart = position;\n    } else {\n      ++position;\n    }\n  }\n\n  throw syntaxError(source, position, 'Unterminated string.');\n}\n\n/**\n * Converts four hexidecimal chars to the integer that the\n * string represents. For example, uniCharCode('0','0','0','f')\n * will return 15, and uniCharCode('0','0','f','f') returns 255.\n *\n * Returns a negative number on error, if a char was invalid.\n *\n * This is implemented by noting that char2hex() returns -1 on error,\n * which means the result of ORing the char2hex() will also be negative.\n */\nfunction uniCharCode(a, b, c, d) {\n  return char2hex(a) << 12 | char2hex(b) << 8 | char2hex(c) << 4 | char2hex(d);\n}\n\n/**\n * Converts a hex character to its integer value.\n * '0' becomes 0, '9' becomes 9\n * 'A' becomes 10, 'F' becomes 15\n * 'a' becomes 10, 'f' becomes 15\n *\n * Returns -1 on error.\n */\nfunction char2hex(a) {\n  return a >= 48 && a <= 57 ? a - 48 // 0-9\n  : a >= 65 && a <= 70 ? a - 55 // A-F\n  : a >= 97 && a <= 102 ? a - 87 // a-f\n  : -1;\n}\n\n/**\n * Reads an alphanumeric + underscore name from the source.\n *\n * [_A-Za-z][_0-9A-Za-z]*\n */\nfunction readName(source, start, line, col, prev) {\n  var body = source.body;\n  var bodyLength = body.length;\n  var position = start + 1;\n  var code = 0;\n  while (position !== bodyLength && (code = charCodeAt.call(body, position)) !== null && (code === 95 || // _\n  code >= 48 && code <= 57 || // 0-9\n  code >= 65 && code <= 90 || // A-Z\n  code >= 97 && code <= 122) // a-z\n  ) {\n    ++position;\n  }\n  return new Tok(TokenKind.NAME, start, position, line, col, prev, slice.call(body, start, position));\n}","/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\n/**\n * The set of allowed kind values for AST nodes.\n */\nexport var Kind = Object.freeze({\n  // Name\n  NAME: 'Name',\n\n  // Document\n  DOCUMENT: 'Document',\n  OPERATION_DEFINITION: 'OperationDefinition',\n  VARIABLE_DEFINITION: 'VariableDefinition',\n  VARIABLE: 'Variable',\n  SELECTION_SET: 'SelectionSet',\n  FIELD: 'Field',\n  ARGUMENT: 'Argument',\n\n  // Fragments\n  FRAGMENT_SPREAD: 'FragmentSpread',\n  INLINE_FRAGMENT: 'InlineFragment',\n  FRAGMENT_DEFINITION: 'FragmentDefinition',\n\n  // Values\n  INT: 'IntValue',\n  FLOAT: 'FloatValue',\n  STRING: 'StringValue',\n  BOOLEAN: 'BooleanValue',\n  NULL: 'NullValue',\n  ENUM: 'EnumValue',\n  LIST: 'ListValue',\n  OBJECT: 'ObjectValue',\n  OBJECT_FIELD: 'ObjectField',\n\n  // Directives\n  DIRECTIVE: 'Directive',\n\n  // Types\n  NAMED_TYPE: 'NamedType',\n  LIST_TYPE: 'ListType',\n  NON_NULL_TYPE: 'NonNullType',\n\n  // Type System Definitions\n  SCHEMA_DEFINITION: 'SchemaDefinition',\n  OPERATION_TYPE_DEFINITION: 'OperationTypeDefinition',\n\n  // Type Definitions\n  SCALAR_TYPE_DEFINITION: 'ScalarTypeDefinition',\n  OBJECT_TYPE_DEFINITION: 'ObjectTypeDefinition',\n  FIELD_DEFINITION: 'FieldDefinition',\n  INPUT_VALUE_DEFINITION: 'InputValueDefinition',\n  INTERFACE_TYPE_DEFINITION: 'InterfaceTypeDefinition',\n  UNION_TYPE_DEFINITION: 'UnionTypeDefinition',\n  ENUM_TYPE_DEFINITION: 'EnumTypeDefinition',\n  ENUM_VALUE_DEFINITION: 'EnumValueDefinition',\n  INPUT_OBJECT_TYPE_DEFINITION: 'InputObjectTypeDefinition',\n\n  // Type Extensions\n  SCALAR_TYPE_EXTENSION: 'ScalarTypeExtension',\n  OBJECT_TYPE_EXTENSION: 'ObjectTypeExtension',\n  INTERFACE_TYPE_EXTENSION: 'InterfaceTypeExtension',\n  UNION_TYPE_EXTENSION: 'UnionTypeExtension',\n  ENUM_TYPE_EXTENSION: 'EnumTypeExtension',\n  INPUT_OBJECT_TYPE_EXTENSION: 'InputObjectTypeExtension',\n\n  // Directive Definitions\n  DIRECTIVE_DEFINITION: 'DirectiveDefinition'\n});\n\n/**\n * The enum type representing the possible kind values of AST nodes.\n */","/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\n/**\n * The set of allowed directive location values.\n */\nexport var DirectiveLocation = Object.freeze({\n  // Request Definitions\n  QUERY: 'QUERY',\n  MUTATION: 'MUTATION',\n  SUBSCRIPTION: 'SUBSCRIPTION',\n  FIELD: 'FIELD',\n  FRAGMENT_DEFINITION: 'FRAGMENT_DEFINITION',\n  FRAGMENT_SPREAD: 'FRAGMENT_SPREAD',\n  INLINE_FRAGMENT: 'INLINE_FRAGMENT',\n  // Type System Definitions\n  SCHEMA: 'SCHEMA',\n  SCALAR: 'SCALAR',\n  OBJECT: 'OBJECT',\n  FIELD_DEFINITION: 'FIELD_DEFINITION',\n  ARGUMENT_DEFINITION: 'ARGUMENT_DEFINITION',\n  INTERFACE: 'INTERFACE',\n  UNION: 'UNION',\n  ENUM: 'ENUM',\n  ENUM_VALUE: 'ENUM_VALUE',\n  INPUT_OBJECT: 'INPUT_OBJECT',\n  INPUT_FIELD_DEFINITION: 'INPUT_FIELD_DEFINITION'\n});\n\n/**\n * The enum type representing the directive location values.\n */","/**\n * Copyright (c) 2015-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n *  strict\n */\n\nimport { Source } from './source';\nimport { syntaxError } from '../error';\n\nimport { createLexer, TokenKind, getTokenDesc } from './lexer';\n\n\nimport { Kind } from './kinds';\nimport { DirectiveLocation } from './directiveLocation';\n\n/**\n * Configuration options to control parser behavior\n */\n\n\n/**\n * Given a GraphQL source, parses it into a Document.\n * Throws GraphQLError if a syntax error is encountered.\n */\nexport function parse(source, options) {\n  var sourceObj = typeof source === 'string' ? new Source(source) : source;\n  if (!(sourceObj instanceof Source)) {\n    throw new TypeError('Must provide Source. Received: ' + String(sourceObj));\n  }\n  var lexer = createLexer(sourceObj, options || {});\n  return parseDocument(lexer);\n}\n\n/**\n * Given a string containing a GraphQL value (ex. `[42]`), parse the AST for\n * that value.\n * Throws GraphQLError if a syntax error is encountered.\n *\n * This is useful within tools that operate upon GraphQL Values directly and\n * in isolation of complete GraphQL documents.\n *\n * Consider providing the results to the utility function: valueFromAST().\n */\nexport function parseValue(source, options) {\n  var sourceObj = typeof source === 'string' ? new Source(source) : source;\n  var lexer = createLexer(sourceObj, options || {});\n  expect(lexer, TokenKind.SOF);\n  var value = parseValueLiteral(lexer, false);\n  expect(lexer, TokenKind.EOF);\n  return value;\n}\n\n/**\n * Given a string containing a GraphQL Type (ex. `[Int!]`), parse the AST for\n * that type.\n * Throws GraphQLError if a syntax error is encountered.\n *\n * This is useful within tools that operate upon GraphQL Types directly and\n * in isolation of complete GraphQL documents.\n *\n * Consider providing the results to the utility function: typeFromAST().\n */\nexport function parseType(source, options) {\n  var sourceObj = typeof source === 'string' ? new Source(source) : source;\n  var lexer = createLexer(sourceObj, options || {});\n  expect(lexer, TokenKind.SOF);\n  var type = parseTypeReference(lexer);\n  expect(lexer, TokenKind.EOF);\n  return type;\n}\n\n/**\n * Converts a name lex token into a name parse node.\n */\nfunction parseName(lexer) {\n  var token = expect(lexer, TokenKind.NAME);\n  return {\n    kind: Kind.NAME,\n    value: token.value,\n    loc: loc(lexer, token)\n  };\n}\n\n// Implements the parsing rules in the Document section.\n\n/**\n * Document : Definition+\n */\nfunction parseDocument(lexer) {\n  var start = lexer.token;\n  expect(lexer, TokenKind.SOF);\n  var definitions = [];\n  do {\n    definitions.push(parseDefinition(lexer));\n  } while (!skip(lexer, TokenKind.EOF));\n\n  return {\n    kind: Kind.DOCUMENT,\n    definitions: definitions,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * Definition :\n *   - ExecutableDefinition\n *   - TypeSystemDefinition\n */\nfunction parseDefinition(lexer) {\n  if (peek(lexer, TokenKind.NAME)) {\n    switch (lexer.token.value) {\n      case 'query':\n      case 'mutation':\n      case 'subscription':\n      case 'fragment':\n        return parseExecutableDefinition(lexer);\n      case 'schema':\n      case 'scalar':\n      case 'type':\n      case 'interface':\n      case 'union':\n      case 'enum':\n      case 'input':\n      case 'extend':\n      case 'directive':\n        // Note: The schema definition language is an experimental addition.\n        return parseTypeSystemDefinition(lexer);\n    }\n  } else if (peek(lexer, TokenKind.BRACE_L)) {\n    return parseExecutableDefinition(lexer);\n  } else if (peekDescription(lexer)) {\n    // Note: The schema definition language is an experimental addition.\n    return parseTypeSystemDefinition(lexer);\n  }\n\n  throw unexpected(lexer);\n}\n\n/**\n * ExecutableDefinition :\n *   - OperationDefinition\n *   - FragmentDefinition\n */\nfunction parseExecutableDefinition(lexer) {\n  if (peek(lexer, TokenKind.NAME)) {\n    switch (lexer.token.value) {\n      case 'query':\n      case 'mutation':\n      case 'subscription':\n        return parseOperationDefinition(lexer);\n\n      case 'fragment':\n        return parseFragmentDefinition(lexer);\n    }\n  } else if (peek(lexer, TokenKind.BRACE_L)) {\n    return parseOperationDefinition(lexer);\n  }\n\n  throw unexpected(lexer);\n}\n\n// Implements the parsing rules in the Operations section.\n\n/**\n * OperationDefinition :\n *  - SelectionSet\n *  - OperationType Name? VariableDefinitions? Directives? SelectionSet\n */\nfunction parseOperationDefinition(lexer) {\n  var start = lexer.token;\n  if (peek(lexer, TokenKind.BRACE_L)) {\n    return {\n      kind: Kind.OPERATION_DEFINITION,\n      operation: 'query',\n      name: undefined,\n      variableDefinitions: [],\n      directives: [],\n      selectionSet: parseSelectionSet(lexer),\n      loc: loc(lexer, start)\n    };\n  }\n  var operation = parseOperationType(lexer);\n  var name = void 0;\n  if (peek(lexer, TokenKind.NAME)) {\n    name = parseName(lexer);\n  }\n  return {\n    kind: Kind.OPERATION_DEFINITION,\n    operation: operation,\n    name: name,\n    variableDefinitions: parseVariableDefinitions(lexer),\n    directives: parseDirectives(lexer, false),\n    selectionSet: parseSelectionSet(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * OperationType : one of query mutation subscription\n */\nfunction parseOperationType(lexer) {\n  var operationToken = expect(lexer, TokenKind.NAME);\n  switch (operationToken.value) {\n    case 'query':\n      return 'query';\n    case 'mutation':\n      return 'mutation';\n    case 'subscription':\n      return 'subscription';\n  }\n\n  throw unexpected(lexer, operationToken);\n}\n\n/**\n * VariableDefinitions : ( VariableDefinition+ )\n */\nfunction parseVariableDefinitions(lexer) {\n  return peek(lexer, TokenKind.PAREN_L) ? many(lexer, TokenKind.PAREN_L, parseVariableDefinition, TokenKind.PAREN_R) : [];\n}\n\n/**\n * VariableDefinition : Variable : Type DefaultValue?\n */\nfunction parseVariableDefinition(lexer) {\n  var start = lexer.token;\n  return {\n    kind: Kind.VARIABLE_DEFINITION,\n    variable: parseVariable(lexer),\n    type: (expect(lexer, TokenKind.COLON), parseTypeReference(lexer)),\n    defaultValue: skip(lexer, TokenKind.EQUALS) ? parseValueLiteral(lexer, true) : undefined,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * Variable : $ Name\n */\nfunction parseVariable(lexer) {\n  var start = lexer.token;\n  expect(lexer, TokenKind.DOLLAR);\n  return {\n    kind: Kind.VARIABLE,\n    name: parseName(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * SelectionSet : { Selection+ }\n */\nfunction parseSelectionSet(lexer) {\n  var start = lexer.token;\n  return {\n    kind: Kind.SELECTION_SET,\n    selections: many(lexer, TokenKind.BRACE_L, parseSelection, TokenKind.BRACE_R),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * Selection :\n *   - Field\n *   - FragmentSpread\n *   - InlineFragment\n */\nfunction parseSelection(lexer) {\n  return peek(lexer, TokenKind.SPREAD) ? parseFragment(lexer) : parseField(lexer);\n}\n\n/**\n * Field : Alias? Name Arguments? Directives? SelectionSet?\n *\n * Alias : Name :\n */\nfunction parseField(lexer) {\n  var start = lexer.token;\n\n  var nameOrAlias = parseName(lexer);\n  var alias = void 0;\n  var name = void 0;\n  if (skip(lexer, TokenKind.COLON)) {\n    alias = nameOrAlias;\n    name = parseName(lexer);\n  } else {\n    name = nameOrAlias;\n  }\n\n  return {\n    kind: Kind.FIELD,\n    alias: alias,\n    name: name,\n    arguments: parseArguments(lexer, false),\n    directives: parseDirectives(lexer, false),\n    selectionSet: peek(lexer, TokenKind.BRACE_L) ? parseSelectionSet(lexer) : undefined,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * Arguments[Const] : ( Argument[?Const]+ )\n */\nfunction parseArguments(lexer, isConst) {\n  var item = isConst ? parseConstArgument : parseArgument;\n  return peek(lexer, TokenKind.PAREN_L) ? many(lexer, TokenKind.PAREN_L, item, TokenKind.PAREN_R) : [];\n}\n\n/**\n * Argument[Const] : Name : Value[?Const]\n */\nfunction parseArgument(lexer) {\n  var start = lexer.token;\n  return {\n    kind: Kind.ARGUMENT,\n    name: parseName(lexer),\n    value: (expect(lexer, TokenKind.COLON), parseValueLiteral(lexer, false)),\n    loc: loc(lexer, start)\n  };\n}\n\nfunction parseConstArgument(lexer) {\n  var start = lexer.token;\n  return {\n    kind: Kind.ARGUMENT,\n    name: parseName(lexer),\n    value: (expect(lexer, TokenKind.COLON), parseConstValue(lexer)),\n    loc: loc(lexer, start)\n  };\n}\n\n// Implements the parsing rules in the Fragments section.\n\n/**\n * Corresponds to both FragmentSpread and InlineFragment in the spec.\n *\n * FragmentSpread : ... FragmentName Directives?\n *\n * InlineFragment : ... TypeCondition? Directives? SelectionSet\n */\nfunction parseFragment(lexer) {\n  var start = lexer.token;\n  expect(lexer, TokenKind.SPREAD);\n  if (peek(lexer, TokenKind.NAME) && lexer.token.value !== 'on') {\n    return {\n      kind: Kind.FRAGMENT_SPREAD,\n      name: parseFragmentName(lexer),\n      directives: parseDirectives(lexer, false),\n      loc: loc(lexer, start)\n    };\n  }\n  var typeCondition = void 0;\n  if (lexer.token.value === 'on') {\n    lexer.advance();\n    typeCondition = parseNamedType(lexer);\n  }\n  return {\n    kind: Kind.INLINE_FRAGMENT,\n    typeCondition: typeCondition,\n    directives: parseDirectives(lexer, false),\n    selectionSet: parseSelectionSet(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * FragmentDefinition :\n *   - fragment FragmentName on TypeCondition Directives? SelectionSet\n *\n * TypeCondition : NamedType\n */\nfunction parseFragmentDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'fragment');\n  // Experimental support for defining variables within fragments changes\n  // the grammar of FragmentDefinition:\n  //   - fragment FragmentName VariableDefinitions? on TypeCondition Directives? SelectionSet\n  if (lexer.options.experimentalFragmentVariables) {\n    return {\n      kind: Kind.FRAGMENT_DEFINITION,\n      name: parseFragmentName(lexer),\n      variableDefinitions: parseVariableDefinitions(lexer),\n      typeCondition: (expectKeyword(lexer, 'on'), parseNamedType(lexer)),\n      directives: parseDirectives(lexer, false),\n      selectionSet: parseSelectionSet(lexer),\n      loc: loc(lexer, start)\n    };\n  }\n  return {\n    kind: Kind.FRAGMENT_DEFINITION,\n    name: parseFragmentName(lexer),\n    typeCondition: (expectKeyword(lexer, 'on'), parseNamedType(lexer)),\n    directives: parseDirectives(lexer, false),\n    selectionSet: parseSelectionSet(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * FragmentName : Name but not `on`\n */\nfunction parseFragmentName(lexer) {\n  if (lexer.token.value === 'on') {\n    throw unexpected(lexer);\n  }\n  return parseName(lexer);\n}\n\n// Implements the parsing rules in the Values section.\n\n/**\n * Value[Const] :\n *   - [~Const] Variable\n *   - IntValue\n *   - FloatValue\n *   - StringValue\n *   - BooleanValue\n *   - NullValue\n *   - EnumValue\n *   - ListValue[?Const]\n *   - ObjectValue[?Const]\n *\n * BooleanValue : one of `true` `false`\n *\n * NullValue : `null`\n *\n * EnumValue : Name but not `true`, `false` or `null`\n */\nfunction parseValueLiteral(lexer, isConst) {\n  var token = lexer.token;\n  switch (token.kind) {\n    case TokenKind.BRACKET_L:\n      return parseList(lexer, isConst);\n    case TokenKind.BRACE_L:\n      return parseObject(lexer, isConst);\n    case TokenKind.INT:\n      lexer.advance();\n      return {\n        kind: Kind.INT,\n        value: token.value,\n        loc: loc(lexer, token)\n      };\n    case TokenKind.FLOAT:\n      lexer.advance();\n      return {\n        kind: Kind.FLOAT,\n        value: token.value,\n        loc: loc(lexer, token)\n      };\n    case TokenKind.STRING:\n    case TokenKind.BLOCK_STRING:\n      return parseStringLiteral(lexer);\n    case TokenKind.NAME:\n      if (token.value === 'true' || token.value === 'false') {\n        lexer.advance();\n        return {\n          kind: Kind.BOOLEAN,\n          value: token.value === 'true',\n          loc: loc(lexer, token)\n        };\n      } else if (token.value === 'null') {\n        lexer.advance();\n        return {\n          kind: Kind.NULL,\n          loc: loc(lexer, token)\n        };\n      }\n      lexer.advance();\n      return {\n        kind: Kind.ENUM,\n        value: token.value,\n        loc: loc(lexer, token)\n      };\n    case TokenKind.DOLLAR:\n      if (!isConst) {\n        return parseVariable(lexer);\n      }\n      break;\n  }\n  throw unexpected(lexer);\n}\n\nfunction parseStringLiteral(lexer) {\n  var token = lexer.token;\n  lexer.advance();\n  return {\n    kind: Kind.STRING,\n    value: token.value,\n    block: token.kind === TokenKind.BLOCK_STRING,\n    loc: loc(lexer, token)\n  };\n}\n\nexport function parseConstValue(lexer) {\n  return parseValueLiteral(lexer, true);\n}\n\nfunction parseValueValue(lexer) {\n  return parseValueLiteral(lexer, false);\n}\n\n/**\n * ListValue[Const] :\n *   - [ ]\n *   - [ Value[?Const]+ ]\n */\nfunction parseList(lexer, isConst) {\n  var start = lexer.token;\n  var item = isConst ? parseConstValue : parseValueValue;\n  return {\n    kind: Kind.LIST,\n    values: any(lexer, TokenKind.BRACKET_L, item, TokenKind.BRACKET_R),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ObjectValue[Const] :\n *   - { }\n *   - { ObjectField[?Const]+ }\n */\nfunction parseObject(lexer, isConst) {\n  var start = lexer.token;\n  expect(lexer, TokenKind.BRACE_L);\n  var fields = [];\n  while (!skip(lexer, TokenKind.BRACE_R)) {\n    fields.push(parseObjectField(lexer, isConst));\n  }\n  return {\n    kind: Kind.OBJECT,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ObjectField[Const] : Name : Value[?Const]\n */\nfunction parseObjectField(lexer, isConst) {\n  var start = lexer.token;\n  return {\n    kind: Kind.OBJECT_FIELD,\n    name: parseName(lexer),\n    value: (expect(lexer, TokenKind.COLON), parseValueLiteral(lexer, isConst)),\n    loc: loc(lexer, start)\n  };\n}\n\n// Implements the parsing rules in the Directives section.\n\n/**\n * Directives[Const] : Directive[?Const]+\n */\nfunction parseDirectives(lexer, isConst) {\n  var directives = [];\n  while (peek(lexer, TokenKind.AT)) {\n    directives.push(parseDirective(lexer, isConst));\n  }\n  return directives;\n}\n\n/**\n * Directive[Const] : @ Name Arguments[?Const]?\n */\nfunction parseDirective(lexer, isConst) {\n  var start = lexer.token;\n  expect(lexer, TokenKind.AT);\n  return {\n    kind: Kind.DIRECTIVE,\n    name: parseName(lexer),\n    arguments: parseArguments(lexer, isConst),\n    loc: loc(lexer, start)\n  };\n}\n\n// Implements the parsing rules in the Types section.\n\n/**\n * Type :\n *   - NamedType\n *   - ListType\n *   - NonNullType\n */\nexport function parseTypeReference(lexer) {\n  var start = lexer.token;\n  var type = void 0;\n  if (skip(lexer, TokenKind.BRACKET_L)) {\n    type = parseTypeReference(lexer);\n    expect(lexer, TokenKind.BRACKET_R);\n    type = {\n      kind: Kind.LIST_TYPE,\n      type: type,\n      loc: loc(lexer, start)\n    };\n  } else {\n    type = parseNamedType(lexer);\n  }\n  if (skip(lexer, TokenKind.BANG)) {\n    return {\n      kind: Kind.NON_NULL_TYPE,\n      type: type,\n      loc: loc(lexer, start)\n    };\n  }\n  return type;\n}\n\n/**\n * NamedType : Name\n */\nexport function parseNamedType(lexer) {\n  var start = lexer.token;\n  return {\n    kind: Kind.NAMED_TYPE,\n    name: parseName(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n// Implements the parsing rules in the Type Definition section.\n\n/**\n * TypeSystemDefinition :\n *   - SchemaDefinition\n *   - TypeDefinition\n *   - TypeExtension\n *   - DirectiveDefinition\n *\n * TypeDefinition :\n *   - ScalarTypeDefinition\n *   - ObjectTypeDefinition\n *   - InterfaceTypeDefinition\n *   - UnionTypeDefinition\n *   - EnumTypeDefinition\n *   - InputObjectTypeDefinition\n */\nfunction parseTypeSystemDefinition(lexer) {\n  // Many definitions begin with a description and require a lookahead.\n  var keywordToken = peekDescription(lexer) ? lexer.lookahead() : lexer.token;\n\n  if (keywordToken.kind === TokenKind.NAME) {\n    switch (keywordToken.value) {\n      case 'schema':\n        return parseSchemaDefinition(lexer);\n      case 'scalar':\n        return parseScalarTypeDefinition(lexer);\n      case 'type':\n        return parseObjectTypeDefinition(lexer);\n      case 'interface':\n        return parseInterfaceTypeDefinition(lexer);\n      case 'union':\n        return parseUnionTypeDefinition(lexer);\n      case 'enum':\n        return parseEnumTypeDefinition(lexer);\n      case 'input':\n        return parseInputObjectTypeDefinition(lexer);\n      case 'extend':\n        return parseTypeExtension(lexer);\n      case 'directive':\n        return parseDirectiveDefinition(lexer);\n    }\n  }\n\n  throw unexpected(lexer, keywordToken);\n}\n\nfunction peekDescription(lexer) {\n  return peek(lexer, TokenKind.STRING) || peek(lexer, TokenKind.BLOCK_STRING);\n}\n\n/**\n * Description : StringValue\n */\nfunction parseDescription(lexer) {\n  if (peekDescription(lexer)) {\n    return parseStringLiteral(lexer);\n  }\n}\n\n/**\n * SchemaDefinition : schema Directives[Const]? { OperationTypeDefinition+ }\n */\nfunction parseSchemaDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'schema');\n  var directives = parseDirectives(lexer, true);\n  var operationTypes = many(lexer, TokenKind.BRACE_L, parseOperationTypeDefinition, TokenKind.BRACE_R);\n  return {\n    kind: Kind.SCHEMA_DEFINITION,\n    directives: directives,\n    operationTypes: operationTypes,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * OperationTypeDefinition : OperationType : NamedType\n */\nfunction parseOperationTypeDefinition(lexer) {\n  var start = lexer.token;\n  var operation = parseOperationType(lexer);\n  expect(lexer, TokenKind.COLON);\n  var type = parseNamedType(lexer);\n  return {\n    kind: Kind.OPERATION_TYPE_DEFINITION,\n    operation: operation,\n    type: type,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ScalarTypeDefinition : Description? scalar Name Directives[Const]?\n */\nfunction parseScalarTypeDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  expectKeyword(lexer, 'scalar');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  return {\n    kind: Kind.SCALAR_TYPE_DEFINITION,\n    description: description,\n    name: name,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ObjectTypeDefinition :\n *   Description?\n *   type Name ImplementsInterfaces? Directives[Const]? FieldsDefinition?\n */\nfunction parseObjectTypeDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  expectKeyword(lexer, 'type');\n  var name = parseName(lexer);\n  var interfaces = parseImplementsInterfaces(lexer);\n  var directives = parseDirectives(lexer, true);\n  var fields = parseFieldsDefinition(lexer);\n  return {\n    kind: Kind.OBJECT_TYPE_DEFINITION,\n    description: description,\n    name: name,\n    interfaces: interfaces,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ImplementsInterfaces :\n *   - implements `&`? NamedType\n *   - ImplementsInterfaces & NamedType\n */\nfunction parseImplementsInterfaces(lexer) {\n  var types = [];\n  if (lexer.token.value === 'implements') {\n    lexer.advance();\n    // Optional leading ampersand\n    skip(lexer, TokenKind.AMP);\n    do {\n      types.push(parseNamedType(lexer));\n    } while (skip(lexer, TokenKind.AMP) ||\n    // Legacy support for the SDL?\n    lexer.options.allowLegacySDLImplementsInterfaces && peek(lexer, TokenKind.NAME));\n  }\n  return types;\n}\n\n/**\n * FieldsDefinition : { FieldDefinition+ }\n */\nfunction parseFieldsDefinition(lexer) {\n  // Legacy support for the SDL?\n  if (lexer.options.allowLegacySDLEmptyFields && peek(lexer, TokenKind.BRACE_L) && lexer.lookahead().kind === TokenKind.BRACE_R) {\n    lexer.advance();\n    lexer.advance();\n    return [];\n  }\n  return peek(lexer, TokenKind.BRACE_L) ? many(lexer, TokenKind.BRACE_L, parseFieldDefinition, TokenKind.BRACE_R) : [];\n}\n\n/**\n * FieldDefinition :\n *   - Description? Name ArgumentsDefinition? : Type Directives[Const]?\n */\nfunction parseFieldDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  var name = parseName(lexer);\n  var args = parseArgumentDefs(lexer);\n  expect(lexer, TokenKind.COLON);\n  var type = parseTypeReference(lexer);\n  var directives = parseDirectives(lexer, true);\n  return {\n    kind: Kind.FIELD_DEFINITION,\n    description: description,\n    name: name,\n    arguments: args,\n    type: type,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ArgumentsDefinition : ( InputValueDefinition+ )\n */\nfunction parseArgumentDefs(lexer) {\n  if (!peek(lexer, TokenKind.PAREN_L)) {\n    return [];\n  }\n  return many(lexer, TokenKind.PAREN_L, parseInputValueDef, TokenKind.PAREN_R);\n}\n\n/**\n * InputValueDefinition :\n *   - Description? Name : Type DefaultValue? Directives[Const]?\n */\nfunction parseInputValueDef(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  var name = parseName(lexer);\n  expect(lexer, TokenKind.COLON);\n  var type = parseTypeReference(lexer);\n  var defaultValue = void 0;\n  if (skip(lexer, TokenKind.EQUALS)) {\n    defaultValue = parseConstValue(lexer);\n  }\n  var directives = parseDirectives(lexer, true);\n  return {\n    kind: Kind.INPUT_VALUE_DEFINITION,\n    description: description,\n    name: name,\n    type: type,\n    defaultValue: defaultValue,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * InterfaceTypeDefinition :\n *   - Description? interface Name Directives[Const]? FieldsDefinition?\n */\nfunction parseInterfaceTypeDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  expectKeyword(lexer, 'interface');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  var fields = parseFieldsDefinition(lexer);\n  return {\n    kind: Kind.INTERFACE_TYPE_DEFINITION,\n    description: description,\n    name: name,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * UnionTypeDefinition :\n *   - Description? union Name Directives[Const]? UnionMemberTypes?\n */\nfunction parseUnionTypeDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  expectKeyword(lexer, 'union');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  var types = parseUnionMemberTypes(lexer);\n  return {\n    kind: Kind.UNION_TYPE_DEFINITION,\n    description: description,\n    name: name,\n    directives: directives,\n    types: types,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * UnionMemberTypes :\n *   - = `|`? NamedType\n *   - UnionMemberTypes | NamedType\n */\nfunction parseUnionMemberTypes(lexer) {\n  var types = [];\n  if (skip(lexer, TokenKind.EQUALS)) {\n    // Optional leading pipe\n    skip(lexer, TokenKind.PIPE);\n    do {\n      types.push(parseNamedType(lexer));\n    } while (skip(lexer, TokenKind.PIPE));\n  }\n  return types;\n}\n\n/**\n * EnumTypeDefinition :\n *   - Description? enum Name Directives[Const]? EnumValuesDefinition?\n */\nfunction parseEnumTypeDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  expectKeyword(lexer, 'enum');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  var values = parseEnumValuesDefinition(lexer);\n  return {\n    kind: Kind.ENUM_TYPE_DEFINITION,\n    description: description,\n    name: name,\n    directives: directives,\n    values: values,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * EnumValuesDefinition : { EnumValueDefinition+ }\n */\nfunction parseEnumValuesDefinition(lexer) {\n  return peek(lexer, TokenKind.BRACE_L) ? many(lexer, TokenKind.BRACE_L, parseEnumValueDefinition, TokenKind.BRACE_R) : [];\n}\n\n/**\n * EnumValueDefinition : Description? EnumValue Directives[Const]?\n *\n * EnumValue : Name\n */\nfunction parseEnumValueDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  return {\n    kind: Kind.ENUM_VALUE_DEFINITION,\n    description: description,\n    name: name,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * InputObjectTypeDefinition :\n *   - Description? input Name Directives[Const]? InputFieldsDefinition?\n */\nfunction parseInputObjectTypeDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  expectKeyword(lexer, 'input');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  var fields = parseInputFieldsDefinition(lexer);\n  return {\n    kind: Kind.INPUT_OBJECT_TYPE_DEFINITION,\n    description: description,\n    name: name,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * InputFieldsDefinition : { InputValueDefinition+ }\n */\nfunction parseInputFieldsDefinition(lexer) {\n  return peek(lexer, TokenKind.BRACE_L) ? many(lexer, TokenKind.BRACE_L, parseInputValueDef, TokenKind.BRACE_R) : [];\n}\n\n/**\n * TypeExtension :\n *   - ScalarTypeExtension\n *   - ObjectTypeExtension\n *   - InterfaceTypeExtension\n *   - UnionTypeExtension\n *   - EnumTypeExtension\n *   - InputObjectTypeDefinition\n */\nfunction parseTypeExtension(lexer) {\n  var keywordToken = lexer.lookahead();\n\n  if (keywordToken.kind === TokenKind.NAME) {\n    switch (keywordToken.value) {\n      case 'scalar':\n        return parseScalarTypeExtension(lexer);\n      case 'type':\n        return parseObjectTypeExtension(lexer);\n      case 'interface':\n        return parseInterfaceTypeExtension(lexer);\n      case 'union':\n        return parseUnionTypeExtension(lexer);\n      case 'enum':\n        return parseEnumTypeExtension(lexer);\n      case 'input':\n        return parseInputObjectTypeExtension(lexer);\n    }\n  }\n\n  throw unexpected(lexer, keywordToken);\n}\n\n/**\n * ScalarTypeExtension :\n *   - extend scalar Name Directives[Const]\n */\nfunction parseScalarTypeExtension(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'extend');\n  expectKeyword(lexer, 'scalar');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  if (directives.length === 0) {\n    throw unexpected(lexer);\n  }\n  return {\n    kind: Kind.SCALAR_TYPE_EXTENSION,\n    name: name,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ObjectTypeExtension :\n *  - extend type Name ImplementsInterfaces? Directives[Const]? FieldsDefinition\n *  - extend type Name ImplementsInterfaces? Directives[Const]\n *  - extend type Name ImplementsInterfaces\n */\nfunction parseObjectTypeExtension(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'extend');\n  expectKeyword(lexer, 'type');\n  var name = parseName(lexer);\n  var interfaces = parseImplementsInterfaces(lexer);\n  var directives = parseDirectives(lexer, true);\n  var fields = parseFieldsDefinition(lexer);\n  if (interfaces.length === 0 && directives.length === 0 && fields.length === 0) {\n    throw unexpected(lexer);\n  }\n  return {\n    kind: Kind.OBJECT_TYPE_EXTENSION,\n    name: name,\n    interfaces: interfaces,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * InterfaceTypeExtension :\n *   - extend interface Name Directives[Const]? FieldsDefinition\n *   - extend interface Name Directives[Const]\n */\nfunction parseInterfaceTypeExtension(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'extend');\n  expectKeyword(lexer, 'interface');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  var fields = parseFieldsDefinition(lexer);\n  if (directives.length === 0 && fields.length === 0) {\n    throw unexpected(lexer);\n  }\n  return {\n    kind: Kind.INTERFACE_TYPE_EXTENSION,\n    name: name,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * UnionTypeExtension :\n *   - extend union Name Directives[Const]? UnionMemberTypes\n *   - extend union Name Directives[Const]\n */\nfunction parseUnionTypeExtension(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'extend');\n  expectKeyword(lexer, 'union');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  var types = parseUnionMemberTypes(lexer);\n  if (directives.length === 0 && types.length === 0) {\n    throw unexpected(lexer);\n  }\n  return {\n    kind: Kind.UNION_TYPE_EXTENSION,\n    name: name,\n    directives: directives,\n    types: types,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * EnumTypeExtension :\n *   - extend enum Name Directives[Const]? EnumValuesDefinition\n *   - extend enum Name Directives[Const]\n */\nfunction parseEnumTypeExtension(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'extend');\n  expectKeyword(lexer, 'enum');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  var values = parseEnumValuesDefinition(lexer);\n  if (directives.length === 0 && values.length === 0) {\n    throw unexpected(lexer);\n  }\n  return {\n    kind: Kind.ENUM_TYPE_EXTENSION,\n    name: name,\n    directives: directives,\n    values: values,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * InputObjectTypeExtension :\n *   - extend input Name Directives[Const]? InputFieldsDefinition\n *   - extend input Name Directives[Const]\n */\nfunction parseInputObjectTypeExtension(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'extend');\n  expectKeyword(lexer, 'input');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer, true);\n  var fields = parseInputFieldsDefinition(lexer);\n  if (directives.length === 0 && fields.length === 0) {\n    throw unexpected(lexer);\n  }\n  return {\n    kind: Kind.INPUT_OBJECT_TYPE_EXTENSION,\n    name: name,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * DirectiveDefinition :\n *   - Description? directive @ Name ArgumentsDefinition? on DirectiveLocations\n */\nfunction parseDirectiveDefinition(lexer) {\n  var start = lexer.token;\n  var description = parseDescription(lexer);\n  expectKeyword(lexer, 'directive');\n  expect(lexer, TokenKind.AT);\n  var name = parseName(lexer);\n  var args = parseArgumentDefs(lexer);\n  expectKeyword(lexer, 'on');\n  var locations = parseDirectiveLocations(lexer);\n  return {\n    kind: Kind.DIRECTIVE_DEFINITION,\n    description: description,\n    name: name,\n    arguments: args,\n    locations: locations,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * DirectiveLocations :\n *   - `|`? DirectiveLocation\n *   - DirectiveLocations | DirectiveLocation\n */\nfunction parseDirectiveLocations(lexer) {\n  // Optional leading pipe\n  skip(lexer, TokenKind.PIPE);\n  var locations = [];\n  do {\n    locations.push(parseDirectiveLocation(lexer));\n  } while (skip(lexer, TokenKind.PIPE));\n  return locations;\n}\n\n/*\n * DirectiveLocation :\n *   - ExecutableDirectiveLocation\n *   - TypeSystemDirectiveLocation\n *\n * ExecutableDirectiveLocation : one of\n *   `QUERY`\n *   `MUTATION`\n *   `SUBSCRIPTION`\n *   `FIELD`\n *   `FRAGMENT_DEFINITION`\n *   `FRAGMENT_SPREAD`\n *   `INLINE_FRAGMENT`\n *\n * TypeSystemDirectiveLocation : one of\n *   `SCHEMA`\n *   `SCALAR`\n *   `OBJECT`\n *   `FIELD_DEFINITION`\n *   `ARGUMENT_DEFINITION`\n *   `INTERFACE`\n *   `UNION`\n *   `ENUM`\n *   `ENUM_VALUE`\n *   `INPUT_OBJECT`\n *   `INPUT_FIELD_DEFINITION`\n */\nfunction parseDirectiveLocation(lexer) {\n  var start = lexer.token;\n  var name = parseName(lexer);\n  if (DirectiveLocation.hasOwnProperty(name.value)) {\n    return name;\n  }\n  throw unexpected(lexer, start);\n}\n\n// Core parsing utility functions\n\n/**\n * Returns a location object, used to identify the place in\n * the source that created a given parsed object.\n */\nfunction loc(lexer, startToken) {\n  if (!lexer.options.noLocation) {\n    return new Loc(startToken, lexer.lastToken, lexer.source);\n  }\n}\n\nfunction Loc(startToken, endToken, source) {\n  this.start = startToken.start;\n  this.end = endToken.end;\n  this.startToken = startToken;\n  this.endToken = endToken;\n  this.source = source;\n}\n\n// Print a simplified form when appearing in JSON/util.inspect.\nLoc.prototype.toJSON = Loc.prototype.inspect = function toJSON() {\n  return { start: this.start, end: this.end };\n};\n\n/**\n * Determines if the next token is of a given kind\n */\nfunction peek(lexer, kind) {\n  return lexer.token.kind === kind;\n}\n\n/**\n * If the next token is of the given kind, return true after advancing\n * the lexer. Otherwise, do not change the parser state and return false.\n */\nfunction skip(lexer, kind) {\n  var match = lexer.token.kind === kind;\n  if (match) {\n    lexer.advance();\n  }\n  return match;\n}\n\n/**\n * If the next token is of the given kind, return that token after advancing\n * the lexer. Otherwise, do not change the parser state and throw an error.\n */\nfunction expect(lexer, kind) {\n  var token = lexer.token;\n  if (token.kind === kind) {\n    lexer.advance();\n    return token;\n  }\n  throw syntaxError(lexer.source, token.start, 'Expected ' + kind + ', found ' + getTokenDesc(token));\n}\n\n/**\n * If the next token is a keyword with the given value, return that token after\n * advancing the lexer. Otherwise, do not change the parser state and return\n * false.\n */\nfunction expectKeyword(lexer, value) {\n  var token = lexer.token;\n  if (token.kind === TokenKind.NAME && token.value === value) {\n    lexer.advance();\n    return token;\n  }\n  throw syntaxError(lexer.source, token.start, 'Expected \"' + value + '\", found ' + getTokenDesc(token));\n}\n\n/**\n * Helper function for creating an error when an unexpected lexed token\n * is encountered.\n */\nfunction unexpected(lexer, atToken) {\n  var token = atToken || lexer.token;\n  return syntaxError(lexer.source, token.start, 'Unexpected ' + getTokenDesc(token));\n}\n\n/**\n * Returns a possibly empty list of parse nodes, determined by\n * the parseFn. This list begins with a lex token of openKind\n * and ends with a lex token of closeKind. Advances the parser\n * to the next lex token after the closing token.\n */\nfunction any(lexer, openKind, parseFn, closeKind) {\n  expect(lexer, openKind);\n  var nodes = [];\n  while (!skip(lexer, closeKind)) {\n    nodes.push(parseFn(lexer));\n  }\n  return nodes;\n}\n\n/**\n * Returns a non-empty list of parse nodes, determined by\n * the parseFn. This list begins with a lex token of openKind\n * and ends with a lex token of closeKind. Advances the parser\n * to the next lex token after the closing token.\n */\nfunction many(lexer, openKind, parseFn, closeKind) {\n  expect(lexer, openKind);\n  var nodes = [parseFn(lexer)];\n  while (!skip(lexer, closeKind)) {\n    nodes.push(parseFn(lexer));\n  }\n  return nodes;\n}"],"sourceRoot":""}